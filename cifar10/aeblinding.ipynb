{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '1'\n",
    "from numpy.random import seed\n",
    "import random\n",
    "random.seed(1)\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "class Autoencoder(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 activation='relu',\n",
    "                 init='glorot_uniform',\n",
    "                 verbose=1):\n",
    "        '''\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "        The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        activation: activation, not applied to Input, last layer of the encoder, and Output layers\n",
    "        '''\n",
    "        self.dims = dims\n",
    "        self.act = activation\n",
    "        self.init = init\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"Fully connected auto-encoder model, symmetric.\n",
    "        return:\n",
    "            (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "        \"\"\"\n",
    "        input_img = Input(shape=(32, 32, 3))\n",
    "        \n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        self.encoded = encoded\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        decoded = Add()([input_img, decoded])\n",
    "        \n",
    "        ae = Model(inputs=input_img, outputs=decoded, name='AE')\n",
    "        encoder = Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "        return ae, encoder\n",
    "\n",
    "    def train_and_save(self, X,\n",
    "                       weights_save_name,\n",
    "                       lr=0.001,\n",
    "                       batch_size=32,\n",
    "                       epochs=250,\n",
    "                       loss='mse'):\n",
    "        if os.path.exists(weights_save_name):\n",
    "            logging.info('weights file exists, no need to train pure AE')\n",
    "        else:\n",
    "            logging.debug(f'AE train_and_save lr: {lr}')\n",
    "            logging.debug(f'AE train_and_save batch_size: {batch_size}')\n",
    "            logging.debug(f'AE train_and_save epochs: {epochs}')\n",
    "\n",
    "            verbose = self.verbose\n",
    "\n",
    "            autoencoder, encoder = self.build()\n",
    "\n",
    "            pretrain_optimizer = Adam(lr=lr)\n",
    "\n",
    "            autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "\n",
    "            utils.create_parent_folder(weights_save_name)\n",
    "\n",
    "            mcp_save = ModelCheckpoint(weights_save_name,\n",
    "                                    monitor='loss',\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=True,\n",
    "                                    verbose=verbose,\n",
    "                                    mode='min')\n",
    "\n",
    "            hist = autoencoder.fit(X, X,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=1,\n",
    "                                callbacks=[mcp_save, logger.LoggingCallback(logging.debug)])\n",
    "\n",
    "    def evaluate_quality(self, X_old, y_old, model_save_name):\n",
    "        if not os.path.exists(model_save_name):\n",
    "            self.train_and_save(X_old, model_save_name)\n",
    "\n",
    "        K.clear_session()\n",
    "        autoencoder, encoder = self.build()\n",
    "        encoder.load_weights(model_save_name, by_name=True)\n",
    "        logging.debug(f'Load weights from {model_save_name}')\n",
    "        latent = encoder.predict(X_old)\n",
    "\n",
    "        best_acc = 0\n",
    "        best_n_init = 10\n",
    "        num_classes = len(np.unique(y_old))\n",
    "        logging.debug(f'KMeans k = {num_classes}')\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        for n_init in range(10, 110, 10):\n",
    "            kmeans = KMeans(n_clusters=num_classes, n_init=n_init,\n",
    "                            random_state=42, n_jobs=-1)\n",
    "            y_pred = kmeans.fit_predict(latent)\n",
    "            acc = utils.get_cluster_acc(y_old, y_pred)\n",
    "            logging.debug(f'KMeans n_init: {n_init}, acc: {acc}')\n",
    "            if acc > best_acc:\n",
    "                best_n_init = best_n_init\n",
    "                best_acc = acc\n",
    "        logging.info(f'best accuracy of KMeans on latent data: {best_acc} with n_init {best_n_init}')\n",
    "        return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train[0])\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "x_train = x_train[:30000]\n",
    "y_train = y_train[:30000]\n",
    "x_test = x_test[:30000]\n",
    "y_test = y_test[:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x_train, y_train,batch_size):\n",
    "    batch_count = len(x_train)/batch_size\n",
    "    shuffler = np.random.permutation(len(x_train))\n",
    "    x_ret = x_train[shuffler]\n",
    "    y_ret = y_train[shuffler]\n",
    "    return batch_count, x_ret, y_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--path_dir PATH_DIR] [--type TYPE]\n",
      "                             [--epochs EPOCHS] [--trainable TRAINABLE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/chhabra4/.local/share/jupyter/runtime/kernel-f497e008-51de-4ee6-b7dc-9cca70a1e2f9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "import tensorflow as tf\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "if LooseVersion(keras.__version__) >= LooseVersion('2.0.0'):\n",
    "\tfrom keras.layers import Conv2D\n",
    "else:\n",
    "\tfrom keras.layers import Convolution2D\n",
    "\n",
    "# import argparse\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import os\n",
    "from setup_cifar import CIFAR\n",
    "# from tensorflow.python.platform import flags\n",
    "# FLAGS = flags.FLAGS\n",
    "IMAGE_ROWS = 32\n",
    "IMAGE_COLS = 32\n",
    "NUM_CHANNELS  = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def set_mnist_flags():\n",
    "\t# try:\n",
    "\t#     flags.DEFINE_integer('BATCH_SIZE', 64, 'Size of training batches')\n",
    "\t# except argparse.ArgumentError:\n",
    "\t#     pass\n",
    "\tflags.DEFINE_integer('BATCH_SIZE', 128, 'Size of training batches')\n",
    "\tflags.DEFINE_integer('NUM_CLASSES', 10, 'Number of classification classes')\n",
    "\tflags.DEFINE_integer('IMAGE_ROWS', 28, 'Input row dimension')\n",
    "\tflags.DEFINE_integer('IMAGE_COLS', 28, 'Input column dimension')\n",
    "\tflags.DEFINE_integer('NUM_CHANNELS', 1, 'Input depth dimension')\n",
    "\n",
    "\n",
    "def data_mnist(one_hot=True):\n",
    "\t\"\"\"\n",
    "\tPreprocess MNIST dataset\n",
    "\t\"\"\"\n",
    "\t# the data, shuffled and split between train and test sets\n",
    "\t(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\ty_train = y_train\n",
    "\n",
    "\n",
    "\tX_train = X_train.reshape(X_train.shape[0],\n",
    "\t\t\t\t\t\t\t  IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t  IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t  NUM_CHANNELS)\n",
    "\n",
    "\tX_test = X_test.reshape(X_test.shape[0],\n",
    "\t\t\t\t\t\t\tIMAGE_ROWS,\n",
    "\t\t\t\t\t\t\tIMAGE_COLS,\n",
    "\t\t\t\t\t\t\tNUM_CHANNELS)\n",
    "\n",
    "\tX_train = X_train.astype('float32')\n",
    "\tX_test = X_test.astype('float32')\n",
    "\tX_train /= 255 - 0.5\n",
    "\tX_test /= 255 -0.5\n",
    "\tprint('X_train shape:', X_train.shape)\n",
    "\tprint(X_train.shape[0], 'train samples')\n",
    "\tprint(X_test.shape[0], 'test samples')\n",
    "\n",
    "\tprint(\"Loaded MNIST test data.\")\n",
    "\n",
    "\tif one_hot:\n",
    "\t\t# convert class vectors to binary class matrices\n",
    "\t\ty_train = np_utils.to_categorical(y_train, NUM_CLASSES).astype(np.float32)\n",
    "\t\ty_test = np_utils.to_categorical(y_test, NUM_CLASSES).astype(np.float32)\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test\n",
    "\n",
    "# carlini model, use it as target model\n",
    "def modelA(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\t\n",
    "\tmodel.add(Conv2D(64, (3, 3),\n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(128, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(128, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelB(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dropout(0.2, input_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\tIMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\tNUM_CHANNELS)))\n",
    "\tmodel.add(Convolution2D(64, (8, 8),\n",
    "\t\t\t\t\t\t\tsubsample=(2, 2),\n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(128, (6, 6),\n",
    "\t\t\t\t\t\t\tsubsample=(2, 2),\n",
    "\t\t\t\t\t\t\tborder_mode='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(128, (5, 5),\n",
    "\t\t\t\t\t\t\tsubsample=(1, 1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))  #14\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "\n",
    "def modelC(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(128, (3, 3),\n",
    "\t\t\t\t\t\t\tborder_mode='valid',\n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))  #14\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelD(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding='same',\n",
    "\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(32, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelE(input_ph):\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(48, 3, 3, \n",
    "\t\t\t\t\t\t\tborder_mode='same', \n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(48, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Convolution2D(96, 3, 3, \n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(96, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Convolution2D(192, 3, 3,\n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(192, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "\n",
    "def model_cifar10(input_ph,type=1):\n",
    "\t\"\"\"\n",
    "\tDefines MNIST model using Keras sequential model\n",
    "\t\"\"\"\n",
    "\n",
    "\tmodels = [modelA, modelB, modelC, modelD, modelE]\n",
    "\tmodel = models[type]\n",
    "\treturn model(input_ph)\n",
    "\n",
    "\n",
    "def data_gen_mnist(X_train):\n",
    "\tdatagen = ImageDataGenerator()\n",
    "\n",
    "\tdatagen.fit(X_train)\n",
    "\treturn datagen\n",
    "\n",
    "# a unified framework for all mnist models\n",
    "\n",
    "\n",
    "def main(path_dir,trainable,type,epochs):\n",
    "\t# load the data first\n",
    "\tx = tf.placeholder(tf.float32, shape=(None, 32, 32, 3)) \n",
    "\tdata_augmentation = True\n",
    "\tdata = CIFAR()\n",
    "\tX_train, Y_train, X_test, Y_test = data.train_data, data.train_labels, data.test_data, data.test_labels\n",
    "\tmodel_names = ['modelA','modelB','modelC','modelD','modelE']\n",
    "\tmodel, logits_tensor = model_cifar10(input_ph = x, type = type)\n",
    "\tpath_dir = '' # put your file path for simple cifar10 models. THIS IS ONLY NEEDED WHEN TRAINING YOUR MODEL FROM SCRATCH\n",
    "\t# initiate RMSprop optimizer\n",
    "\t# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\topt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\t# Let's train the model using RMSprop\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=opt,\n",
    "\t\t\t\tmetrics=['accuracy'])\n",
    "\tbatch_size = 128\n",
    "\tif trainable:\n",
    "\t\tif not data_augmentation:\n",
    "\t\t\tprint('Not using data augmentation.')\n",
    "\t\t\tmodel.fit(X_train, Y_train,\n",
    "\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\tshuffle=True)\n",
    "\t\telse:\n",
    "\t\t\tprint('Using real-time data augmentation.')\n",
    "\t\t\t# This will do preprocessing and realtime data augmentation:\n",
    "\t\t\tdatagen = ImageDataGenerator(\n",
    "\t\t\t\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
    "\t\t\t\tsamplewise_center=False,  # set each sample mean to 0\n",
    "\t\t\t\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "\t\t\t\tsamplewise_std_normalization=False,  # divide each input by its std\n",
    "\t\t\t\tzca_whitening=False,  # apply ZCA whitening\n",
    "\t\t\t\tzca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "\t\t\t\trotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "\t\t\t\t# randomly shift images horizontally (fraction of total width)\n",
    "\t\t\t\twidth_shift_range=0.1,\n",
    "\t\t\t\t# randomly shift images vertically (fraction of total height)\n",
    "\t\t\t\theight_shift_range=0.1,\n",
    "\t\t\t\tshear_range=0.,  # set range for random shear\n",
    "\t\t\t\tzoom_range=0.,  # set range for random zoom\n",
    "\t\t\t\tchannel_shift_range=0.,  # set range for random channel shifts\n",
    "\t\t\t\t# set mode for filling points outside the input boundaries\n",
    "\t\t\t\tfill_mode='nearest',\n",
    "\t\t\t\tcval=0.,  # value used for fill_mode = \"constant\"\n",
    "\t\t\t\thorizontal_flip=True,  # randomly flip images\n",
    "\t\t\t\tvertical_flip=False,  # randomly flip images\n",
    "\t\t\t\t# set rescaling factor (applied before any other transformation)\n",
    "\t\t\t\trescale=None,\n",
    "\t\t\t\t# set function that will be applied on each input\n",
    "\t\t\t\tpreprocessing_function=None,\n",
    "\t\t\t\t# image data format, either \"channels_first\" or \"channels_last\"\n",
    "\t\t\t\tdata_format=None,\n",
    "\t\t\t\t# fraction of images reserved for validation (strictly between 0 and 1)\n",
    "\t\t\t\tvalidation_split=0.0)\n",
    "\n",
    "\t\t\t# Compute quantities required for feature-wise normalization\n",
    "\t\t\t# (std, mean, and principal components if ZCA whitening is applied).\n",
    "\t\t\tdatagen.fit(X_train)\n",
    "\n",
    "\t\t\t# Fit the model on the batches generated by datagen.flow().\n",
    "\t\t\tmodel.fit_generator(datagen.flow(X_train, Y_train,\n",
    "\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size),\n",
    "\t\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\t\t\t\tworkers=4)\n",
    "\t\t# save model and weights\n",
    "\t\tmodel_path = path_dir + model_names[type]+'.h5'\n",
    "\t\tmodel.save(model_path)\n",
    "\t\tprint('Saved trained model at %s ' % model_path)\n",
    "\telse:\n",
    "\t\tmodel = load_model(path_dir + model_names[type]+'.h5')\n",
    "\n",
    "\ttemp = np.argmax(model.predict(X_test),axis=1)\n",
    "\taccuracy = accuracy_score(np.argmax(Y_test,axis=1), temp)\n",
    "\tprint(\"oracle model accuracy:\",accuracy)\n",
    "\tscore = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "\t# Score trained model.\n",
    "\tscores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\tprint('Test loss:', scores[0])\n",
    "\tprint('Test accuracy:', scores[1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport argparse\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument(\"--path_dir\", type=str, default = \"model/cifar10/\",help=\"path to model\")\n",
    "\tparser.add_argument(\"--type\", type=int, help=\"model type\", default=1)\n",
    "\tparser.add_argument(\"--epochs\", type=int, default=50, help=\"number of epochs\")\n",
    "\tparser.add_argument(\"--trainable\", type=int, default = 1, help=\"decide if to train or directly load models\")\n",
    "\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\tmain(args.path_dir, args.trainable,args.type,args.epochs)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "class cifar10_models_simple1(object):\n",
    "\tdef __init__(self, sess, test_batch_size, type = 1,use_softmax = True, x = None, is_training=None,\\\n",
    "\t\t keep_prob=None,load_existing = False, model_name = 'modelA', loss = 'cw'):\n",
    "\t\tself.x = x\n",
    "\t\tself.sess = sess\n",
    "\t\tself.is_training = is_training\n",
    "\t\tself.keep_prob = keep_prob\n",
    "\t\tself.test_batch_size = test_batch_size\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.old_vars = set(tf.global_variables())\n",
    "\t\tif load_existing:\n",
    "\t\t\tsave_dir = 'CIFAR10_models/Normal_simple_models' # TODO: put your own ROOT directory of simple cifar10 models\n",
    "\t\t\tfilepath = os.path.join(save_dir, model_name+'.h5')\n",
    "\t\t\tfilepath = 'CIFAR10_models/Normal_simple_models/simple2/saved'\n",
    "\t\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\t\tmodel = load_model(filepath)\n",
    "\t\t\t\t#model._make_predict_function()\n",
    "\t\t\t\tself.model = model\n",
    "\t\t\t\tmodel = KerasModelWrapper(model)\n",
    "\t\t\t\tself.predictions = model.get_logits(self.x)\n",
    "\t\telse:\n",
    "\t\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\t\tmodel, preds = model_cifar10(input_ph = x, type = type)\n",
    "\t\t\t\tself.model = model\n",
    "\t\t\t\tself.predictions = preds\n",
    "\t\tself.new_vars = set(tf.global_variables())\n",
    "\t\tself.var_list = self.new_vars - self.old_vars\n",
    "\t\tself.probs = tf.nn.softmax(logits = self.predictions)\n",
    "\t\tself.eval_preds = tf.argmax(self.predictions, 1)\n",
    "\t\tself.y_target = tf.placeholder(tf.int64, shape=None) # tensor.shape (?,)\n",
    "\t\tself.eval_percent_adv = tf.equal(self.eval_preds, self.y_target) # one-to-one comparison\n",
    "\n",
    "\n",
    "\tdef load_weights(self):\n",
    "\t\t#print(mapping2)\n",
    "\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\tsave_dir = 'CIFAR10_models/Normal_simple_models' # TODO: put your own ROOT directory of simple cifar10 models\n",
    "\t\t\tfilepath = 'CIFAR10_models/Normal_simple_models/simple2/saved'\n",
    "\t\t\tself.model.load_weights(filepath)\n",
    "\t\t\t#model._make_predict_function()\n",
    "\t\t\t#self.model = model\n",
    "\t\t\t#model = KerasModelWrapper(model)\n",
    "\t\t\t#self.predictions = model.get_logits(self.x)\n",
    "\t\t\t#self.probs = tf.nn.softmax(logits = self.predictions)\n",
    "\t\t\t#output = tf.identity(self.probs)\n",
    "\t\t\t#return output\n",
    "            \n",
    "\n",
    "\tdef save_everything(self):\n",
    "\t\th = self.model.save('CIFAR10_models/Normal_simple_models/simple2/saved')\n",
    "\t\tprint(h)\n",
    "\n",
    "\tdef calcu_acc(self,data,lab):\n",
    "\t\tbatch_size = self.test_batch_size\n",
    "\t\t#numpy operation to get prediction value\n",
    "\t\tcorr_preds = 0\n",
    "\t\tnum_batches = int(math.ceil(len(data) / batch_size))\n",
    "\t\tfor ibatch in range(num_batches):\n",
    "\t\t\tbstart = ibatch * batch_size\n",
    "\t\t\tbend = min(bstart + batch_size, len(data))\n",
    "\t\t\tdata_batch = data[bstart:bend,:]\n",
    "\t\t\tlab_batch = lab[bstart:bend]\n",
    "\t\t\t# acc calculation\n",
    "\t\t\tpreds = self.sess.run(self.predictions,feed_dict = {self.x:data_batch})\n",
    "\t\t\tcorr_preds += np.sum(np.argmax(lab_batch,axis = 1) == np.argmax(preds,axis = 1))\n",
    "\t\treturn corr_preds/len(data)\n",
    "\n",
    "\tdef predict_prob(self,data):\n",
    "\t\tbatch_size = self.test_batch_size\n",
    "\t\tprobs = []\n",
    "\t\tnum_batches = int(math.ceil(len(data) / batch_size))\n",
    "\t\tfor ibatch in range(num_batches):\n",
    "\t\t\tbstart = ibatch * batch_size\n",
    "\t\t\tbend = min(bstart + batch_size, len(data))\n",
    "\t\t\tdata_batch = data[bstart:bend,:]\n",
    "\t\t\t# acc calculation\n",
    "\t\t\tprob = self.sess.run(self.probs,feed_dict = {self.x:data_batch})\n",
    "\t\t\tprobs.extend(prob)\n",
    "\t\treturn np.array(probs) \n",
    "\tdef pred_class(self,data):\n",
    "\t\tpreds = self.predict_prob(data)\n",
    "\t\tlabels = np.argmax(preds,axis = 1)\n",
    "\t\treturn labels\n",
    "\n",
    "\tdef eval_adv(self, adv, target_class):\n",
    "\t\tfeed_dict = {self.x: adv, self.y_target: target_class}\n",
    "\t\tpadv = self.sess.run(self.eval_percent_adv, feed_dict=feed_dict)\n",
    "\t\treturn padv\n",
    "\n",
    "\tdef get_loss(self, data, labels,class_num = 10):\n",
    "\t\tif len(labels.shape) == 1:\n",
    "\t\t\tlabels = np_utils.to_categorical(labels, class_num)\n",
    "\t\tfeed_dict = {self.x: data, self.y: labels}\n",
    "\t\tloss_val = self.sess.run(self.loss, feed_dict = feed_dict)\n",
    "\t\treturn loss_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[array([[1.01481592e-02, 9.02265951e-04, 5.56485504e-02, 9.61109921e-02,\n",
      "        2.54448038e-02, 1.95823777e-02, 7.71196842e-01, 3.82890739e-03,\n",
      "        1.62217598e-02, 9.15372162e-04],\n",
      "       [4.37106501e-04, 2.61574751e-03, 3.96338919e-06, 2.32017446e-05,\n",
      "        5.25345740e-08, 2.51373467e-06, 6.52457555e-09, 8.40115172e-06,\n",
      "        4.35338030e-03, 9.92555559e-01],\n",
      "       [7.46670961e-02, 6.41951337e-04, 5.83638554e-04, 7.27261358e-05,\n",
      "        1.77397320e-04, 2.29943780e-05, 3.02832450e-05, 5.57952677e-04,\n",
      "        8.39151721e-03, 9.14854348e-01],\n",
      "       [1.12772236e-08, 4.33854552e-09, 9.31090108e-06, 4.59966623e-06,\n",
      "        9.99934316e-01, 1.99548831e-05, 5.64594075e-06, 2.62103204e-05,\n",
      "        1.93373006e-09, 2.61356501e-08],\n",
      "       [5.88382045e-13, 9.99999881e-01, 6.88999316e-20, 1.76768447e-17,\n",
      "        1.41663105e-23, 1.12170966e-20, 1.13765096e-18, 1.25550869e-19,\n",
      "        5.92179300e-14, 1.50216039e-07],\n",
      "       [2.56637179e-07, 9.99785006e-01, 1.50327473e-09, 7.65537678e-08,\n",
      "        1.46114880e-12, 5.07963804e-09, 6.07130630e-08, 3.77747389e-09,\n",
      "        2.14597591e-07, 2.14322412e-04],\n",
      "       [2.86469944e-02, 7.09124142e-04, 8.55287552e-01, 5.07190675e-02,\n",
      "        4.20757234e-02, 4.22835723e-03, 3.68085108e-03, 2.01594201e-03,\n",
      "        3.96517804e-03, 8.67116917e-03],\n",
      "       [1.25700509e-11, 3.65119800e-13, 2.73264249e-07, 7.53354570e-08,\n",
      "        3.02892091e-04, 2.01757593e-05, 6.28855162e-11, 9.99676585e-01,\n",
      "        2.12237183e-14, 1.09619269e-12],\n",
      "       [5.94751000e-01, 3.86444190e-05, 4.75490000e-04, 3.92853399e-05,\n",
      "        1.95971234e-06, 5.70944167e-06, 1.82224485e-05, 8.93238175e-05,\n",
      "        4.04314131e-01, 2.66181014e-04],\n",
      "       [3.09840292e-02, 4.04109247e-04, 1.03425770e-03, 6.97886765e-01,\n",
      "        2.63548661e-02, 7.41125420e-02, 5.21921378e-04, 1.21317707e-01,\n",
      "        1.28292451e-02, 3.45544890e-02]], dtype=float32)]\n",
      "[[6 9 9 4 1 1 2 7 0 3]]\n",
      "[[1.01481592e-02 9.02265951e-04 5.56485504e-02 9.61109921e-02\n",
      "  2.54448038e-02 1.95823777e-02 7.71196842e-01 3.82890739e-03\n",
      "  1.62217598e-02 9.15372162e-04]\n",
      " [4.37106501e-04 2.61574751e-03 3.96338919e-06 2.32017446e-05\n",
      "  5.25345740e-08 2.51373467e-06 6.52457555e-09 8.40115172e-06\n",
      "  4.35338030e-03 9.92555559e-01]\n",
      " [7.46670961e-02 6.41951337e-04 5.83638554e-04 7.27261358e-05\n",
      "  1.77397320e-04 2.29943780e-05 3.02832450e-05 5.57952677e-04\n",
      "  8.39151721e-03 9.14854348e-01]\n",
      " [1.12772236e-08 4.33854552e-09 9.31090108e-06 4.59966623e-06\n",
      "  9.99934316e-01 1.99548831e-05 5.64594075e-06 2.62103204e-05\n",
      "  1.93373006e-09 2.61356501e-08]\n",
      " [5.88382045e-13 9.99999881e-01 6.88999316e-20 1.76768447e-17\n",
      "  1.41663105e-23 1.12170966e-20 1.13765096e-18 1.25550869e-19\n",
      "  5.92179300e-14 1.50216039e-07]\n",
      " [2.56637179e-07 9.99785006e-01 1.50327473e-09 7.65537678e-08\n",
      "  1.46114880e-12 5.07963804e-09 6.07130630e-08 3.77747389e-09\n",
      "  2.14597591e-07 2.14322412e-04]\n",
      " [2.86469944e-02 7.09124142e-04 8.55287552e-01 5.07190675e-02\n",
      "  4.20757234e-02 4.22835723e-03 3.68085108e-03 2.01594201e-03\n",
      "  3.96517804e-03 8.67116917e-03]\n",
      " [1.25700509e-11 3.65119800e-13 2.73264249e-07 7.53354570e-08\n",
      "  3.02892091e-04 2.01757593e-05 6.28855162e-11 9.99676585e-01\n",
      "  2.12237183e-14 1.09619269e-12]\n",
      " [5.94751000e-01 3.86444190e-05 4.75490000e-04 3.92853399e-05\n",
      "  1.95971234e-06 5.70944167e-06 1.82224485e-05 8.93238175e-05\n",
      "  4.04314131e-01 2.66181014e-04]\n",
      " [3.09840292e-02 4.04109247e-04 1.03425770e-03 6.97886765e-01\n",
      "  2.63548661e-02 7.41125420e-02 5.21921378e-04 1.21317707e-01\n",
      "  1.28292451e-02 3.45544890e-02]]\n",
      "[[1.01481592e-02 9.02265951e-04 5.56485504e-02 9.61109921e-02\n",
      "  2.54448038e-02 1.95823777e-02 7.71196842e-01 3.82890739e-03\n",
      "  1.62217598e-02 9.15372162e-04]\n",
      " [4.37106501e-04 2.61574751e-03 3.96338919e-06 2.32017446e-05\n",
      "  5.25345740e-08 2.51373467e-06 6.52457555e-09 8.40115172e-06\n",
      "  4.35338030e-03 9.92555559e-01]\n",
      " [7.46670961e-02 6.41951337e-04 5.83638554e-04 7.27261358e-05\n",
      "  1.77397320e-04 2.29943780e-05 3.02832450e-05 5.57952677e-04\n",
      "  8.39151721e-03 9.14854348e-01]\n",
      " [1.12772236e-08 4.33854552e-09 9.31090108e-06 4.59966623e-06\n",
      "  9.99934316e-01 1.99548831e-05 5.64594075e-06 2.62103204e-05\n",
      "  1.93373006e-09 2.61356501e-08]\n",
      " [5.88382045e-13 9.99999881e-01 6.88999316e-20 1.76768447e-17\n",
      "  1.41663105e-23 1.12170966e-20 1.13765096e-18 1.25550869e-19\n",
      "  5.92179300e-14 1.50216039e-07]\n",
      " [2.56637179e-07 9.99785006e-01 1.50327473e-09 7.65537678e-08\n",
      "  1.46114880e-12 5.07963804e-09 6.07130630e-08 3.77747389e-09\n",
      "  2.14597591e-07 2.14322412e-04]\n",
      " [2.86469944e-02 7.09124142e-04 8.55287552e-01 5.07190675e-02\n",
      "  4.20757234e-02 4.22835723e-03 3.68085108e-03 2.01594201e-03\n",
      "  3.96517804e-03 8.67116917e-03]\n",
      " [1.25700509e-11 3.65119800e-13 2.73264249e-07 7.53354570e-08\n",
      "  3.02892091e-04 2.01757593e-05 6.28855162e-11 9.99676585e-01\n",
      "  2.12237183e-14 1.09619269e-12]\n",
      " [5.94751000e-01 3.86444190e-05 4.75490000e-04 3.92853399e-05\n",
      "  1.95971234e-06 5.70944167e-06 1.82224485e-05 8.93238175e-05\n",
      "  4.04314131e-01 2.66181014e-04]\n",
      " [3.09840292e-02 4.04109247e-04 1.03425770e-03 6.97886765e-01\n",
      "  2.63548661e-02 7.41125420e-02 5.21921378e-04 1.21317707e-01\n",
      "  1.28292451e-02 3.45544890e-02]]\n",
      "[6 9 9 4 1 1 2 7 0 3 4 7 7 0 9 9 9 3 6 6]\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [7]\n",
      " [8]\n",
      " [3]\n",
      " [4]\n",
      " [7]\n",
      " [7]\n",
      " [2]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "class_num = 10\n",
    "image_size = 32\n",
    "num_channels = 3\n",
    "test_batch_size = 10\n",
    "x = tf.placeholder(tf.float32, shape=(None, image_size, image_size, num_channels))\n",
    "y = tf.placeholder(tf.float32, shape=(None, class_num))\n",
    "input_ = x\n",
    "\n",
    "target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = input_, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "\n",
    "output = tf.identity(target_model2.probs)\n",
    "# for i in tf.trainable_variables():\n",
    "#     mapping2[i.name[:-2]] = i\n",
    "#     #print(i.name)\n",
    "\n",
    "# print(mapping2)\n",
    "with sess as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    target_model2.load_weights()\n",
    "    #yb = sess.run([target_model2.predictions],feed_dict = {input_ : x_train[:10]})\n",
    "    #print(yb)\n",
    "    lb = sess.run([output],feed_dict = {input_ : x_train[:10]})\n",
    "    print(lb)\n",
    "    print(np.argmax(lb, axis=2))\n",
    "    yb,tb = sess.run([target_model2.probs,output],feed_dict = {input_ : x_train[:10]})\n",
    "    print(yb)\n",
    "    print(tb)\n",
    "    pro = target_model2.pred_class(x_train[:20])\n",
    "    print(pro)\n",
    "    print(y_train[:20])\n",
    "#     target_model3.load_weights()\n",
    "#     pro = target_model3.pred_class(x_train[20:30])\n",
    "#     print(pro)\n",
    "#     print(y_train[20:30])\n",
    "#     target_model2.save_everything()\n",
    "\n",
    "#tf.train.Saver(var_list=mapping).save(sess, 'CIFAR10_models/Normal_simple_models/simple/cp1')\n",
    "    #target_model2.save_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "from cifar10_simple_models import cifar10_models_simple\n",
    "\n",
    "tvars_vals = []\n",
    "\n",
    "class ContrastiveAE(object):\n",
    "    def __init__(self, optimizer, lr, dims = 1, verbose=1):\n",
    "        self.dims = dims\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.verbose = verbose\n",
    "        print(\"init\")\n",
    "    \n",
    "    def visualize(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        ae = Autoencoder(self.dims)\n",
    "        ae_model, encoder_model = ae.build()\n",
    "        input_ = ae_model.get_input_at(0)\n",
    "        noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_abs =tf.math.abs(noise)\n",
    "        noise_img = tf.add(input_, noise)\n",
    "        noise_img_clipped = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput = ae_model(noise_img_clipped)\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            ae_model.load_weights('./query-blinding-11-just-weights')\n",
    "            \n",
    "            feed_dict = {\n",
    "                input_: x_train\n",
    "            }\n",
    "            output, input_with_noise, noise_vis = sess.run([aeoutput, noise_img_clipped, noise_abs], feed_dict=feed_dict)\n",
    "            #output = np.array(output)\n",
    "#             print(output[0].shape)\n",
    "#             print(output[0][0].shape)\n",
    "            #print(output)\n",
    "            img = Image.fromarray((output[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeoutput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((input_with_noise[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeinput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((noise_vis[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('noise.png')\n",
    "            img.show()\n",
    "            #ae_model.save(\"saved_autoencoder_qb\")\n",
    "    \n",
    "    def evalLoad(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        sess = tf.Session(config=config)\n",
    "        K.set_session(sess)\n",
    "        \n",
    "        #ae = Autoencoder(self.dims)\n",
    "#         ae = Autoencoder(self.dims)\n",
    "#         ae_model, encoder_model = ae.build()\n",
    "        #ae_model.load_weights('./query-blinding-11-just-weights')\n",
    "        \n",
    "        noise_img = Input(shape=(32, 32, 3))\n",
    "        target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = noise_img, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "        target_model2.load_weights()\n",
    "        ae_model = load_model('./query-blinding-11-whole-model')\n",
    "        #ae_model.load_weights('./query-blinding-11-just-weights')\n",
    "    \n",
    "        op = ae_model.predict(x_train)\n",
    "        #print(op)\n",
    "        c = target_model2.pred_class(op)\n",
    "        print(c)\n",
    "        d = target_model2.pred_class(x_train)\n",
    "        print(d)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def evaluate(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        sess = tf.Session(config=config)\n",
    "        K.set_session(sess)\n",
    "        \n",
    "        ae = Autoencoder(self.dims)\n",
    "        ae_model, encoder_model = ae.build()\n",
    "        input_ = ae_model.get_input_at(0)\n",
    "        noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_abs =tf.math.abs(noise)\n",
    "        noise_img = tf.add(input_, noise)\n",
    "        noise_img_clipped = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput = ae_model(noise_img_clipped)\n",
    "        \n",
    "        noise_second = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_img_second = tf.add(input_, noise_second)\n",
    "        noise_img_second = tf.clip_by_value(noise_img_second, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput_second = ae_model(noise_img_second)\n",
    "        \n",
    "        target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = aeoutput, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "        \n",
    "        output = tf.identity(target_model2.probs, name='my_output')\n",
    "        \n",
    "        z = tf.shape(input_)[0]\n",
    "        aeoutput_mul = aeoutput\n",
    "        aeoutput_mul = tf.reshape(aeoutput_mul, [-1, 32*32*3])\n",
    "        aeoutput_second_mul = aeoutput_second\n",
    "        aeoutput_second_mul = tf.reshape(aeoutput_second_mul, [-1, 32*32*3])\n",
    "        aediff = aeoutput_second_mul - aeoutput_mul\n",
    "        l2_norm = tf.norm(aeoutput_second_mul - aeoutput_mul, ord='euclidean', axis=-1)\n",
    "        l2_norm_sq = tf.pow(l2_norm, 2)\n",
    "        l2_norm_re = tf.reduce_mean(l2_norm_sq)\n",
    "        l2_norm_mi = tf.math.minimum(l2_norm_re, 1000)\n",
    "        \n",
    "        #dist = tf.sqrt(tf.reduce_sum(tf.square(aeoutput_second_mul - aeoutput_mul), 1))\n",
    "        #l2_norm = tf.reduce_mean(dist)\n",
    "#         l2_norm_test = l2_norm\n",
    "#         l2_norm = tf.pow(l2_norm, 2)\n",
    "        \n",
    "        with sess as sess:\n",
    "            ae_model.load_weights('./query-blinding-10-just-weights')\n",
    "            target_model2.load_weights()\n",
    "            \n",
    "            feed_dict = {\n",
    "                input_: x_train\n",
    "            }\n",
    "            \n",
    "            proboutput, l2dist, l2_norm_sq1, l2_norm_re1, l2_norm_mi1 = sess.run([output, l2_norm, l2_norm_sq, l2_norm_re, l2_norm_mi], feed_dict=feed_dict)\n",
    "            z = np.argmax(proboutput, axis=1)\n",
    "            #print(y_train)\n",
    "            eq = 0\n",
    "            for i in range(len(y_train)):\n",
    "                if y_train[i][0] == z[i]:\n",
    "                    eq += 1\n",
    "                    #print(str(i) + \"th was equal\")\n",
    "            print(eq)\n",
    "            print(l2_norm_mi1)\n",
    "    \n",
    "    def evaluateSame(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        sess = tf.Session(config=config)\n",
    "        K.set_session(sess)\n",
    "        \n",
    "        ae = Autoencoder(self.dims)\n",
    "        ae_model, encoder_model = ae.build()\n",
    "        input_ = ae_model.get_input_at(0)\n",
    "        noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_abs =tf.math.abs(noise)\n",
    "        noise_img = tf.add(input_, noise)\n",
    "        noise_img_clipped = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput = ae_model(noise_img_clipped)\n",
    "        aeoutput2 = ae_model(noise_img_clipped)\n",
    "        \n",
    "        noise_second = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_img_second = tf.add(input_, noise_second)\n",
    "        noise_img_second = tf.clip_by_value(noise_img_second, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput_second = ae_model(noise_img_second)\n",
    "        \n",
    "        target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = aeoutput, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "        \n",
    "        output = tf.identity(target_model2.probs, name='my_output')\n",
    "        \n",
    "        z = tf.shape(input_)[0]\n",
    "        aeoutput_mul = aeoutput\n",
    "        aeoutput_mul = tf.reshape(aeoutput_mul, [-1, 32*32*3])\n",
    "        aeoutput_second_mul = aeoutput2\n",
    "        aeoutput_second_mul = tf.reshape(aeoutput_second_mul, [-1, 32*32*3])\n",
    "        aediff = aeoutput_second_mul - aeoutput_mul\n",
    "        l2_norm = tf.norm(aeoutput_second_mul - aeoutput_mul, ord='euclidean', axis=-1)\n",
    "        l2_norm_sq = tf.pow(l2_norm, 2)\n",
    "        l2_norm_re = tf.reduce_mean(l2_norm_sq)\n",
    "        l2_norm_mi = tf.math.minimum(l2_norm_re, 1000)\n",
    "        \n",
    "        #dist = tf.sqrt(tf.reduce_sum(tf.square(aeoutput_second_mul - aeoutput_mul), 1))\n",
    "        #l2_norm = tf.reduce_mean(dist)\n",
    "#         l2_norm_test = l2_norm\n",
    "#         l2_norm = tf.pow(l2_norm, 2)\n",
    "        \n",
    "        with sess as sess:\n",
    "            ae_model.load_weights('./query-blinding-11-just-weights')\n",
    "            target_model2.load_weights()\n",
    "            \n",
    "            feed_dict = {\n",
    "                input_: x_train\n",
    "            }\n",
    "            \n",
    "            proboutput, l2dist, l2_norm_sq1, l2_norm_re1, l2_norm_mi1 = sess.run([output, l2_norm, l2_norm_sq, l2_norm_re, l2_norm_mi], feed_dict=feed_dict)\n",
    "            z = np.argmax(proboutput, axis=1)\n",
    "            #print(y_train)\n",
    "            eq = 0\n",
    "            for i in range(len(y_train)):\n",
    "                if y_train[i][0] == z[i]:\n",
    "                    eq += 1\n",
    "            print(eq)\n",
    "            print(l2_norm_mi1)\n",
    "    \n",
    "    def train(self, x_train, y_train,\n",
    "              lambda_1, batch_size, epochs, similar_ratio, margin,\n",
    "              weights_save_name, display_interval):\n",
    "        \"\"\"Train an autoencoder with standard mse loss + contrastive loss.\n",
    "        Arguments:\n",
    "            X_train {numpy.ndarray} -- feature vectors of the training data\n",
    "            y_train {numpy.ndarray} -- ground-truth labels of the training data\n",
    "            lambda_1 {float} -- balance factor for the autoencoder reconstruction loss and contrastive loss\n",
    "            batch_size {int} -- number of samples in each batch (note we only use **half of batch_size**\n",
    "                                from the training data).\n",
    "            epochs {int} -- No. of maximum epochs.\n",
    "            similar_ratio {float} -- ratio of similar samples, use 0.25 for now.\n",
    "            margin {float} -- the hyper-parameter m.\n",
    "            weights_save_name {str} -- file path to save the best weights files.\n",
    "            display_interval {int} -- print traning logs per {display_interval} epoches\n",
    "        \"\"\"\n",
    "        print(\"hello\")\n",
    "        if False:\n",
    "            logging.info('weights file exists, no need to train contrastive AE')\n",
    "        else:\n",
    "            tf.reset_default_graph()\n",
    "            \n",
    "            sess = tf.Session(config=config)\n",
    "            K.set_session(sess)\n",
    "           \n",
    "            lambda_1_tensor = tf.placeholder(tf.float32)\n",
    "            ae = Autoencoder(self.dims)\n",
    "            ae_model, encoder_model = ae.build()\n",
    "\n",
    "            input_ = ae_model.get_input_at(0)\n",
    "            aclabels = tf.placeholder(tf.int32, [None, 1])\n",
    "            noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img = tf.add(input_, noise)\n",
    "            noise_img = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "            print(noise_img.shape)\n",
    "            noise_second = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img_second = tf.add(input_, noise_second)\n",
    "            noise_img_second = tf.clip_by_value(noise_img_second, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "\n",
    "            aeoutput = ae_model(noise_img)\n",
    "            aeoutput_second = ae_model(noise_img_second)\n",
    "            ae_loss = tf.keras.losses.MSE(noise_img, ae_model(noise_img)) # ae.out equals ae_model(input_)\n",
    "            ae_loss = tf.reduce_mean(ae_loss)\n",
    "            \n",
    "            model_dir = \"./\"\n",
    "#             target_model2 = Load_Madry_Model(tf.Session(config=config), model_dir, noise_img, bias = 0.5, scale = 255)\n",
    "#             target_model3 = Load_Madry_Model(tf.Session(config=config), model_dir, aeoutput, bias = 0.5, scale = 255)\n",
    "            t_m_o = tf.placeholder(tf.float32, shape=(None, 10)) \n",
    "            target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = noise_img, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "            target_model3 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = aeoutput, \n",
    "                                                              load_existing=False,model_name='modelA')            \n",
    "            #print(target_model2.var_list)\n",
    "            output = tf.identity(target_model2.probs, name='my_output')\n",
    "            output2 = tf.identity(target_model3.probs, name='my_output2')\n",
    "            \n",
    "            aeoutput_mul = aeoutput*28\n",
    "            aeoutput_mul = tf.reshape(aeoutput_mul, [-1, 32*32*3])\n",
    "            aeoutput_second_mul = aeoutput_second*28\n",
    "            aeoutput_second_mul = tf.reshape(aeoutput_second_mul, [-1, 32*32*3])\n",
    "            l2_norm = tf.norm(aeoutput_second_mul - aeoutput_mul, ord='euclidean', axis=-1)\n",
    "            l2_norm_sq = tf.pow(l2_norm, 2)\n",
    "            l2_norm_re = tf.reduce_mean(l2_norm_sq)\n",
    "            l2_norm_mi = tf.math.minimum(l2_norm_re, 700000)\n",
    "            \n",
    "            \n",
    "            loss_crossentropy = tf.keras.losses.sparse_categorical_crossentropy(aclabels, output2)\n",
    "            loss_crossentropy = tf.reduce_mean(loss_crossentropy)\n",
    "            loss = loss_crossentropy - l2_norm_mi\n",
    "            #loss = - l2_norm\n",
    "            \n",
    "            train_op = self.optimizer.minimize(loss, var_list=list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))\n",
    "            print(list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))\n",
    "            # Start training\n",
    "            with sess as sess:\n",
    "                loss_batch, aux_batch, ce_batch = [], [], []\n",
    "                contrastive_loss_batch, ae_loss_batch = [], []\n",
    "                \n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                target_model2.load_weights()\n",
    "                target_model3.load_weights()\n",
    "                min_loss = np.inf \n",
    "                \n",
    "               \n",
    "                # epoch training loop\n",
    "                for epoch in range(100):\n",
    "                    epoch_time = time.time()\n",
    "                    # split data into batches\n",
    "                    batch_size = 100\n",
    "                    batch_count, batch_x, batch_y = batch_data(x_train, y_train, batch_size)\n",
    "                    batch_count = int(batch_count)\n",
    "                    print(\"BC: %d\" % batch_count)\n",
    "                    # batch training loop\n",
    "                    \n",
    "                    for b in range(batch_count):\n",
    "                        logging.debug(f'b: {b}')\n",
    "                        #add random noise to x_train (start with 0.01 first)\n",
    "                        feed_dict = {\n",
    "                            input_: batch_x[b*batch_size:b*batch_size + batch_size],\n",
    "                            lambda_1_tensor: lambda_1,\n",
    "                            aclabels: batch_y[b*batch_size:b*batch_size + batch_size],\n",
    "                        }\n",
    "#                         loss1, _, ae_loss1, \\\n",
    "#                             encoded1, labelled = sess.run([loss, train_op, ae_loss, ae.encoded, target_model2.model.softmax_pred], feed_dict=feed_dict)\n",
    "                        labelled, labelled2,loss1,ae_loss1,l2_norm_sq1,l2_norm_re1,loss_ce,_ = sess.run([output,output2,loss,l2_norm_mi,l2_norm_sq,l2_norm_re,loss_crossentropy,train_op], feed_dict=feed_dict)\n",
    "                        #print(np.argmax(labelled, axis=1))\n",
    "                        #print(np.argmax(labelled2, axis=1))\n",
    "                        #print(labelled)\n",
    "                        #print(*y_train)\n",
    "#                         print(ae_loss1)\n",
    "#                         print(l2_norm_sq1)\n",
    "#                         print(l2_norm_re1)\n",
    "                        \n",
    "#                         if b % 10 == 0:\n",
    "#                             print(np.argmax(labelled2, axis=1))\n",
    "#                             print(batch_y[b*batch_size:b*batch_size + batch_size])\n",
    "                        \n",
    "                        loss_batch.append(loss1)\n",
    "                        ae_loss_batch.append(ae_loss1)\n",
    "                        ce_batch.append(loss_ce)\n",
    "                    \n",
    "                    if math.isnan(np.mean(loss_batch)):\n",
    "                        logging.error('NaN value in loss')\n",
    "                    \n",
    "                    current_loss = np.mean(loss_batch)\n",
    "                    print(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "                                    f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "                                    f'ae {np.mean(ce_batch)} -- ' + \\\n",
    "                                    f'time {time.time() - epoch_time}')\n",
    "                    \n",
    "                    if np.mean(ae_loss_batch) > 600000:\n",
    "                        print(\"saving weights\")\n",
    "                        ae_model.save('./query-blinding-10-whole-model')\n",
    "                        ae_model.save_weights('./query-blinding-10-just-weights')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "print(len(x_train))\n",
    "x_train_t = x_train[:2000]\n",
    "y_train_t = y_train[:2000]\n",
    "cae.train(x_train_t, y_train_t,\n",
    "                1e-1, 1, 1, 1, 1,\n",
    "                1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "30000\n",
      "hello\n",
      "(?, 32, 32, 3)\n",
      "[<tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/moving_mean:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/moving_variance:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_3/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_2/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/moving_mean:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_4/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/moving_variance:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 64, 16) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_5/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 32, 3) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>]\n",
      "BC: 20\n",
      "Epoch 0: loss -10164.4296875 -- ae 10169.4892578125 -- ae 5.060019016265869 -- time 1.0541322231292725\n",
      "BC: 20\n",
      "Epoch 1: loss -60806.2265625 -- ae 60813.3203125 -- ae 7.093804359436035 -- time 0.4228661060333252\n",
      "BC: 20\n",
      "Epoch 2: loss -163993.015625 -- ae 164001.078125 -- ae 8.061300277709961 -- time 0.42304539680480957\n",
      "BC: 20\n",
      "Epoch 3: loss -235508.296875 -- ae 235516.953125 -- ae 8.638750076293945 -- time 0.4108905792236328\n",
      "BC: 20\n",
      "Epoch 4: loss -288167.5625 -- ae 288176.53125 -- ae 8.976593971252441 -- time 0.40738892555236816\n",
      "BC: 20\n",
      "Epoch 5: loss -320323.0625 -- ae 320332.3125 -- ae 9.219254493713379 -- time 0.41397619247436523\n",
      "BC: 20\n",
      "Epoch 6: loss -353007.59375 -- ae 353017.0 -- ae 9.412954330444336 -- time 0.4049041271209717\n",
      "BC: 20\n",
      "Epoch 7: loss -383416.59375 -- ae 383426.15625 -- ae 9.5753173828125 -- time 0.4180750846862793\n",
      "BC: 20\n",
      "Epoch 8: loss -412227.375 -- ae 412237.0625 -- ae 9.724786758422852 -- time 0.40796470642089844\n",
      "BC: 20\n",
      "Epoch 9: loss -439741.90625 -- ae 439751.75 -- ae 9.859121322631836 -- time 0.4085869789123535\n",
      "BC: 20\n",
      "Epoch 10: loss -462182.75 -- ae 462192.71875 -- ae 10.003373146057129 -- time 0.41898083686828613\n",
      "BC: 20\n",
      "Epoch 11: loss -480443.65625 -- ae 480453.8125 -- ae 10.133316040039062 -- time 0.4283592700958252\n",
      "BC: 20\n",
      "Epoch 12: loss -497079.125 -- ae 497089.40625 -- ae 10.265015602111816 -- time 0.4139406681060791\n",
      "BC: 20\n",
      "Epoch 13: loss -511547.3125 -- ae 511557.59375 -- ae 10.333853721618652 -- time 0.4237232208251953\n",
      "BC: 20\n",
      "Epoch 14: loss -524017.5 -- ae 524028.0 -- ae 10.476408958435059 -- time 0.41497182846069336\n",
      "BC: 20\n",
      "Epoch 15: loss -534971.6875 -- ae 534982.3125 -- ae 10.564226150512695 -- time 0.4139385223388672\n",
      "BC: 20\n",
      "Epoch 16: loss -544677.125 -- ae 544687.75 -- ae 10.613028526306152 -- time 0.43215513229370117\n",
      "BC: 20\n",
      "Epoch 17: loss -553305.625 -- ae 553316.25 -- ae 10.661190032958984 -- time 0.42583680152893066\n",
      "BC: 20\n",
      "Epoch 18: loss -561025.75 -- ae 561036.4375 -- ae 10.70854663848877 -- time 0.4148132801055908\n",
      "BC: 20\n",
      "Epoch 19: loss -567973.8125 -- ae 567984.625 -- ae 10.751888275146484 -- time 0.4218568801879883\n",
      "BC: 20\n",
      "Epoch 20: loss -574250.375 -- ae 574261.125 -- ae 10.792193412780762 -- time 0.42940783500671387\n",
      "BC: 20\n",
      "Epoch 21: loss -579965.6875 -- ae 579976.5625 -- ae 10.821064949035645 -- time 0.41730403900146484\n",
      "BC: 20\n",
      "Epoch 22: loss -585184.125 -- ae 585195.0 -- ae 10.841835021972656 -- time 0.4276399612426758\n",
      "BC: 20\n",
      "Epoch 23: loss -589967.625 -- ae 589978.5625 -- ae 10.86172103881836 -- time 0.42815065383911133\n",
      "BC: 20\n",
      "Epoch 24: loss -594368.5 -- ae 594379.375 -- ae 10.881640434265137 -- time 0.4214003086090088\n",
      "BC: 20\n",
      "Epoch 25: loss -598408.125 -- ae 598419.0625 -- ae 10.906532287597656 -- time 0.41118931770324707\n",
      "BC: 20\n",
      "Epoch 26: loss -602139.0 -- ae 602150.0 -- ae 10.945578575134277 -- time 0.4272174835205078\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 27: loss -605578.4375 -- ae 605589.4375 -- ae 10.97321605682373 -- time 0.44106292724609375\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 28: loss -608830.125 -- ae 608841.125 -- ae 10.999119758605957 -- time 0.4238734245300293\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 29: loss -611167.375 -- ae 611178.375 -- ae 11.035225868225098 -- time 0.41300177574157715\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 30: loss -613622.125 -- ae 613633.25 -- ae 11.081287384033203 -- time 0.4199965000152588\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 31: loss -616309.125 -- ae 616320.3125 -- ae 11.113531112670898 -- time 0.4346656799316406\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 32: loss -618831.125 -- ae 618842.25 -- ae 11.153301239013672 -- time 0.41806483268737793\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 33: loss -621218.0625 -- ae 621229.25 -- ae 11.195775985717773 -- time 0.42454099655151367\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 34: loss -623468.625 -- ae 623479.875 -- ae 11.23728084564209 -- time 0.4186854362487793\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 35: loss -625594.1875 -- ae 625605.4375 -- ae 11.272897720336914 -- time 0.4391305446624756\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 36: loss -627604.75 -- ae 627616.0625 -- ae 11.309926986694336 -- time 0.41631174087524414\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 37: loss -629509.625 -- ae 629520.9375 -- ae 11.344024658203125 -- time 0.4225609302520752\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 38: loss -631316.6875 -- ae 631328.0625 -- ae 11.376296997070312 -- time 0.42592859268188477\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 39: loss -633033.5 -- ae 633044.875 -- ae 11.407397270202637 -- time 0.4402127265930176\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 40: loss -634666.4375 -- ae 634677.9375 -- ae 11.435141563415527 -- time 0.42971086502075195\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 41: loss -636221.75 -- ae 636233.25 -- ae 11.462020874023438 -- time 0.4169647693634033\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 42: loss -637704.625 -- ae 637716.1875 -- ae 11.490413665771484 -- time 0.4206051826477051\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 43: loss -639120.125 -- ae 639131.6875 -- ae 11.516029357910156 -- time 0.4129676818847656\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 44: loss -640472.8125 -- ae 640484.3125 -- ae 11.541274070739746 -- time 0.42612195014953613\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 45: loss -641766.5625 -- ae 641778.1875 -- ae 11.566183090209961 -- time 0.4314265251159668\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 46: loss -643005.25 -- ae 643016.9375 -- ae 11.587597846984863 -- time 0.4228339195251465\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 47: loss -644192.375 -- ae 644204.125 -- ae 11.609192848205566 -- time 0.4185147285461426\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 48: loss -645331.125 -- ae 645342.8125 -- ae 11.62960147857666 -- time 0.4218258857727051\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 49: loss -646424.3125 -- ae 646435.9375 -- ae 11.649497032165527 -- time 0.4292147159576416\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 50: loss -647474.5 -- ae 647486.1875 -- ae 11.667974472045898 -- time 0.4299046993255615\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 51: loss -648484.375 -- ae 648496.0625 -- ae 11.686188697814941 -- time 0.45450711250305176\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 52: loss -649456.125 -- ae 649467.8125 -- ae 11.702492713928223 -- time 0.4416682720184326\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 53: loss -650391.9375 -- ae 650403.625 -- ae 11.719399452209473 -- time 0.4372735023498535\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 54: loss -651293.625 -- ae 651305.375 -- ae 11.7354736328125 -- time 0.44318270683288574\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 55: loss -652163.1875 -- ae 652174.875 -- ae 11.750102996826172 -- time 0.44876670837402344\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 56: loss -653002.1875 -- ae 653013.875 -- ae 11.765246391296387 -- time 0.4228193759918213\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 57: loss -653812.3125 -- ae 653824.0625 -- ae 11.778745651245117 -- time 0.42136430740356445\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 58: loss -654594.9375 -- ae 654606.625 -- ae 11.793634414672852 -- time 0.4315495491027832\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 59: loss -655351.4375 -- ae 655363.25 -- ae 11.808095932006836 -- time 0.42579150199890137\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 60: loss -656083.1875 -- ae 656095.0 -- ae 11.821094512939453 -- time 0.4174363613128662\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 61: loss -656791.3125 -- ae 656803.125 -- ae 11.832809448242188 -- time 0.41280078887939453\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 62: loss -657477.0 -- ae 657488.8125 -- ae 11.844876289367676 -- time 0.42647814750671387\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 63: loss -658141.1875 -- ae 658153.0625 -- ae 11.856348037719727 -- time 0.4335637092590332\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 64: loss -658785.0 -- ae 658796.875 -- ae 11.867232322692871 -- time 0.4361915588378906\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 65: loss -659409.25 -- ae 659421.125 -- ae 11.87923812866211 -- time 0.41904640197753906\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 66: loss -660014.875 -- ae 660026.8125 -- ae 11.890629768371582 -- time 0.4292600154876709\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 67: loss -660602.75 -- ae 660614.625 -- ae 11.901555061340332 -- time 0.4167335033416748\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 68: loss -661173.5 -- ae 661185.4375 -- ae 11.91076946258545 -- time 0.4211313724517822\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 69: loss -661728.0 -- ae 661739.9375 -- ae 11.920467376708984 -- time 0.43298768997192383\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 70: loss -662266.875 -- ae 662278.8125 -- ae 11.929488182067871 -- time 0.4157979488372803\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 71: loss -662790.75 -- ae 662802.6875 -- ae 11.937310218811035 -- time 0.43436384201049805\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 72: loss -663300.3125 -- ae 663312.25 -- ae 11.9461030960083 -- time 0.4248788356781006\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 73: loss -663796.125 -- ae 663808.0625 -- ae 11.955357551574707 -- time 0.41121983528137207\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 74: loss -664278.625 -- ae 664290.625 -- ae 11.963523864746094 -- time 0.42106080055236816\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 75: loss -664748.4375 -- ae 664760.4375 -- ae 11.97140121459961 -- time 0.41492724418640137\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 76: loss -665206.125 -- ae 665218.125 -- ae 11.979076385498047 -- time 0.4181184768676758\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 77: loss -665652.0 -- ae 665664.0625 -- ae 11.987091064453125 -- time 0.4204232692718506\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 78: loss -666086.625 -- ae 666098.6875 -- ae 11.99518871307373 -- time 0.4275996685028076\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 79: loss -666510.375 -- ae 666522.4375 -- ae 12.002666473388672 -- time 0.4221522808074951\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 80: loss -666923.75 -- ae 666935.8125 -- ae 12.008938789367676 -- time 0.4242525100708008\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 81: loss -667326.9375 -- ae 667338.9375 -- ae 12.016218185424805 -- time 0.42005228996276855\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 82: loss -667720.375 -- ae 667732.5 -- ae 12.023336410522461 -- time 0.4272956848144531\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 83: loss -668104.625 -- ae 668116.5625 -- ae 12.03006649017334 -- time 0.42262744903564453\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 84: loss -668479.6875 -- ae 668491.75 -- ae 12.035975456237793 -- time 0.4250679016113281\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 85: loss -668846.0625 -- ae 668858.0625 -- ae 12.041714668273926 -- time 0.43177103996276855\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 86: loss -669204.0 -- ae 669216.0625 -- ae 12.047737121582031 -- time 0.421067476272583\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 87: loss -669553.75 -- ae 669565.8125 -- ae 12.053582191467285 -- time 0.4146897792816162\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 88: loss -669895.75 -- ae 669907.875 -- ae 12.059840202331543 -- time 0.41991353034973145\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 89: loss -670230.125 -- ae 670242.125 -- ae 12.065138816833496 -- time 0.4223177433013916\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 90: loss -670557.125 -- ae 670569.1875 -- ae 12.070422172546387 -- time 0.4160652160644531\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 91: loss -670876.9375 -- ae 670889.0625 -- ae 12.075874328613281 -- time 0.42756032943725586\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 92: loss -671190.0 -- ae 671202.125 -- ae 12.08127498626709 -- time 0.41833996772766113\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 93: loss -671496.3125 -- ae 671508.4375 -- ae 12.08703899383545 -- time 0.42977476119995117\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 94: loss -671796.25 -- ae 671808.3125 -- ae 12.092181205749512 -- time 0.4253499507904053\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 95: loss -672089.9375 -- ae 672102.0625 -- ae 12.096688270568848 -- time 0.4246344566345215\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 96: loss -672377.5625 -- ae 672389.6875 -- ae 12.10146713256836 -- time 0.42996716499328613\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 97: loss -672659.25 -- ae 672671.4375 -- ae 12.106514930725098 -- time 0.4152071475982666\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 98: loss -672935.3125 -- ae 672947.4375 -- ae 12.11181354522705 -- time 0.41300272941589355\n",
      "saving weights\n",
      "BC: 20\n",
      "Epoch 99: loss -673205.875 -- ae 673218.0 -- ae 12.11641788482666 -- time 0.425551176071167\n",
      "saving weights\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "print(len(x_train))\n",
    "x_train_t = x_train[:2000]\n",
    "y_train_t = y_train[:2000]\n",
    "cae.train(x_train_t, y_train_t,\n",
    "                1e-1, 1, 1, 1, 1,\n",
    "                1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "x_train_vis = x_train[:1]\n",
    "cae.visualize(x_train_vis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "106\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "x_train_vis = x_test[:1000]\n",
    "y_train_vis = y_test[:1000]\n",
    "cae.evaluate(x_train_vis, y_train_vis)\n",
    "#print(y_train_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
