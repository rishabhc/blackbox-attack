{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "from numpy.random import seed\n",
    "import random\n",
    "random.seed(1)\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "class Autoencoder(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 activation='relu',\n",
    "                 init='glorot_uniform',\n",
    "                 verbose=1):\n",
    "        '''\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "        The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        activation: activation, not applied to Input, last layer of the encoder, and Output layers\n",
    "        '''\n",
    "        self.dims = dims\n",
    "        self.act = activation\n",
    "        self.init = init\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"Fully connected auto-encoder model, symmetric.\n",
    "        return:\n",
    "            (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "        \"\"\"\n",
    "        input_img = Input(shape=(32, 32, 3))\n",
    "        \n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        self.encoded = encoded\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        ae = Model(inputs=input_img, outputs=decoded, name='AE')\n",
    "        encoder = Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "        return ae, encoder\n",
    "\n",
    "    def train_and_save(self, X,\n",
    "                       weights_save_name,\n",
    "                       lr=0.001,\n",
    "                       batch_size=32,\n",
    "                       epochs=250,\n",
    "                       loss='mse'):\n",
    "        if os.path.exists(weights_save_name):\n",
    "            logging.info('weights file exists, no need to train pure AE')\n",
    "        else:\n",
    "            logging.debug(f'AE train_and_save lr: {lr}')\n",
    "            logging.debug(f'AE train_and_save batch_size: {batch_size}')\n",
    "            logging.debug(f'AE train_and_save epochs: {epochs}')\n",
    "\n",
    "            verbose = self.verbose\n",
    "\n",
    "            autoencoder, encoder = self.build()\n",
    "\n",
    "            pretrain_optimizer = Adam(lr=lr)\n",
    "\n",
    "            autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "\n",
    "            utils.create_parent_folder(weights_save_name)\n",
    "\n",
    "            mcp_save = ModelCheckpoint(weights_save_name,\n",
    "                                    monitor='loss',\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=True,\n",
    "                                    verbose=verbose,\n",
    "                                    mode='min')\n",
    "\n",
    "            hist = autoencoder.fit(X, X,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=1,\n",
    "                                callbacks=[mcp_save, logger.LoggingCallback(logging.debug)])\n",
    "\n",
    "    def evaluate_quality(self, X_old, y_old, model_save_name):\n",
    "        if not os.path.exists(model_save_name):\n",
    "            self.train_and_save(X_old, model_save_name)\n",
    "\n",
    "        K.clear_session()\n",
    "        autoencoder, encoder = self.build()\n",
    "        encoder.load_weights(model_save_name, by_name=True)\n",
    "        logging.debug(f'Load weights from {model_save_name}')\n",
    "        latent = encoder.predict(X_old)\n",
    "\n",
    "        best_acc = 0\n",
    "        best_n_init = 10\n",
    "        num_classes = len(np.unique(y_old))\n",
    "        logging.debug(f'KMeans k = {num_classes}')\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        for n_init in range(10, 110, 10):\n",
    "            kmeans = KMeans(n_clusters=num_classes, n_init=n_init,\n",
    "                            random_state=42, n_jobs=-1)\n",
    "            y_pred = kmeans.fit_predict(latent)\n",
    "            acc = utils.get_cluster_acc(y_old, y_pred)\n",
    "            logging.debug(f'KMeans n_init: {n_init}, acc: {acc}')\n",
    "            if acc > best_acc:\n",
    "                best_n_init = best_n_init\n",
    "                best_acc = acc\n",
    "        logging.info(f'best accuracy of KMeans on latent data: {best_acc} with n_init {best_n_init}')\n",
    "        return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveAE(object):\n",
    "    def __init__(self, optimizer, lr, dims = 1, verbose=1):\n",
    "        self.dims = dims\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.verbose = verbose\n",
    "        print(\"init\")\n",
    "\n",
    "    def train(self, X_train, y_train,\n",
    "              lambda_1, batch_size, epochs, similar_ratio, margin,\n",
    "              weights_save_name, display_interval):\n",
    "        \"\"\"Train an autoencoder with standard mse loss + contrastive loss.\n",
    "        Arguments:\n",
    "            X_train {numpy.ndarray} -- feature vectors of the training data\n",
    "            y_train {numpy.ndarray} -- ground-truth labels of the training data\n",
    "            lambda_1 {float} -- balance factor for the autoencoder reconstruction loss and contrastive loss\n",
    "            batch_size {int} -- number of samples in each batch (note we only use **half of batch_size**\n",
    "                                from the training data).\n",
    "            epochs {int} -- No. of maximum epochs.\n",
    "            similar_ratio {float} -- ratio of similar samples, use 0.25 for now.\n",
    "            margin {float} -- the hyper-parameter m.\n",
    "            weights_save_name {str} -- file path to save the best weights files.\n",
    "            display_interval {int} -- print traning logs per {display_interval} epoches\n",
    "        \"\"\"\n",
    "        print(\"hello\")\n",
    "        if False:\n",
    "            logging.info('weights file exists, no need to train contrastive AE')\n",
    "        else:\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "           \n",
    "            lambda_1_tensor = tf.placeholder(tf.float32)\n",
    "            ae = Autoencoder(self.dims)\n",
    "            ae_model, encoder_model = ae.build()\n",
    "\n",
    "            input_ = ae_model.get_input_at(0)\n",
    "            labels = ae_model.get_input_at(0)\n",
    "            # add loss function -- for efficiency and not doubling the network's weights, we pass a batch of samples and\n",
    "            # make the pairs from it at the loss level.\n",
    "#             left_p = tf.convert_to_tensor(list(range(0, int(batch_size / 2))), np.int32)\n",
    "#             right_p = tf.convert_to_tensor(list(range(int(batch_size / 2), batch_size)), np.int32)\n",
    "\n",
    "#             # left_p: indices with all the data in this batch, right_p: half with similar data compared to left_p, half with dissimilar data compared to left_p\n",
    "#             # if batch_size = 16 (but only using 8 samples in this batch):\n",
    "#             # e.g., left_p labels: 1, 2, 4, 8 | 2, 3, 5, 6\n",
    "#             #      right_p labels: 1, 2, 4, 8 | 3, 4, 1, 7\n",
    "#             # check whether labels[left_p] == labels[right_p] for each element\n",
    "#             is_same = tf.cast(tf.equal(tf.gather(labels, left_p), tf.gather(labels, right_p)), tf.float32)\n",
    "#             # NOTE: add a small number like 1e-10 would prevent tf.sqrt() to have 0 values, further leading gradients and loss all NaN.\n",
    "#             # check: https://stackoverflow.com/questions/33712178/tensorflow-nan-bug\n",
    "#             dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.gather(ae.encoded, left_p), tf.gather(ae.encoded, right_p))), 1) + 1e-10) # ||zi - zj||_2\n",
    "#             contrastive_loss = tf.multiply(is_same, dist) # y_ij = 1 means the same class.\n",
    "#             contrastive_loss = contrastive_loss + tf.multiply((tf.constant(1.0) - is_same), tf.nn.relu(margin - dist))  # as relu(z) = max(0, z)\n",
    "#             contrastive_loss = tf.reduce_mean(contrastive_loss)\n",
    "\n",
    "            ae_loss = tf.keras.losses.MSE(input_, ae_model(input_)) # ae.out equals ae_model(input_)\n",
    "            ae_loss = tf.reduce_mean(ae_loss)\n",
    "#             vgg = VGG19(image_shape=(1,32,32,3), input_tensor=input_)\n",
    "#             vgg2 = VGG19_2(image_shape=(1,32,32,3), input_tensor=input_)\n",
    "            \n",
    "#             output = tf.identity(vgg['block5_pool'], name='my_output')\n",
    "#             output2 = tf.identity(vgg2['block5_pool'], name='my_output')\n",
    "            print(\"here\")\n",
    "            # Final loss\n",
    "            loss = ae_loss \n",
    "\n",
    "            train_op = self.optimizer.minimize(ae_loss, var_list=tf.trainable_variables())\n",
    "\n",
    "            # Start training\n",
    "            with tf.Session(config=config) as sess:\n",
    "                loss_batch, aux_batch = [], []\n",
    "                contrastive_loss_batch, ae_loss_batch = [], []\n",
    "                \n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                print(tf.trainable_variables())\n",
    "#                 vgg.load_weights()\n",
    "#                 vgg2.load_weights()\n",
    "                \n",
    "                min_loss = np.inf\n",
    "\n",
    "                # epoch training loop\n",
    "                for epoch in range(10):\n",
    "                    epoch_time = time.time()\n",
    "                    # split data into batches\n",
    "#                     batch_count, batch_x, batch_y = data.epoch_batches(X_train, y_train,\n",
    "#                                                                     batch_size,\n",
    "#                                                                     similar_ratio)\n",
    "#                     # batch training loop\n",
    "                    for b in range(1):\n",
    "                        logging.debug(f'b: {b}')\n",
    "                        feed_dict = {\n",
    "                            input_: x_train,\n",
    "                            labels: y_train,\n",
    "                            lambda_1_tensor: lambda_1\n",
    "                        }\n",
    "                        loss1, _, ae_loss1, \\\n",
    "                            encoded1 = sess.run([loss, train_op, ae_loss, ae.encoded], feed_dict=feed_dict)\n",
    "\n",
    "                        print(f'loss1: {loss1},  aux1: {ae_loss1}')\n",
    "#                         logging.debug(f'contrastive: {contrastive_loss1}, ae: {ae_loss1}')\n",
    "#                         logging.debug(f'epoch-{epoch} dist1[left]: {dist1[0:batch_size // 4]}')\n",
    "#                         logging.debug(f'epoch-{epoch} dist1[right]: {dist1[batch_size // 4:]}')\n",
    "\n",
    "                        loss_batch.append(loss1)\n",
    "#                         aux_batch.append(aux1)\n",
    "#                         contrastive_loss_batch.append(contrastive_loss1)\n",
    "                        ae_loss_batch.append(ae_loss1)\n",
    "\n",
    "                    if math.isnan(np.mean(loss_batch)):\n",
    "                        logging.error('NaN value in loss')\n",
    "                    \n",
    "                    current_loss = np.mean(loss_batch)\n",
    "#                     print(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "#                                     f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "#                                     f'time {time.time() - epoch_time}')\n",
    "                    # print logs each xxx epoch\n",
    "#                     if epoch % display_interval == 0:\n",
    "#                         current_loss = np.mean(loss_batch)\n",
    "#                         logging.info(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "#                                     f'contrastive {np.mean(contrastive_loss_batch)} -- ' + \\\n",
    "#                                     f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "#                                     f'pairs {np.mean(np.sum(np.mean(aux_batch)))} : ' + \\\n",
    "#                                     f'{np.mean(np.sum(1-np.mean(aux_batch)))} -- ' + \\\n",
    "#                                     f'time {time.time() - epoch_time}')\n",
    "#                         loss_batch, aux_batch = [], []\n",
    "#                         contrastive_loss_batch, ae_loss_batch = [], []\n",
    "\n",
    "#                         # save best weights\n",
    "#                         if current_loss < min_loss:\n",
    "#                             logging.info(f'updating best loss from {min_loss} to {current_loss}')\n",
    "#                             min_loss = current_loss\n",
    "#                             ae_model.save_weights(weights_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train[0])\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "x_train = x_train[:30000]\n",
    "y_train = y_train[:30000]\n",
    "x_test = x_test[:30000]\n",
    "y_test = y_test[:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x_train, y_train,batch_size):\n",
    "    batch_count = len(x_train)/batch_size\n",
    "    shuffler = np.random.permutation(len(x_train))\n",
    "    x_ret = x_train[shuffler]\n",
    "    y_ret = y_train[shuffler]\n",
    "    return batch_count, x_ret, y_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "from cifar10_simple_models import cifar10_models_simple\n",
    "\n",
    "tvars_vals = []\n",
    "\n",
    "class ContrastiveAE(object):\n",
    "    def __init__(self, optimizer, lr, dims = 1, verbose=1):\n",
    "        self.dims = dims\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.verbose = verbose\n",
    "        print(\"init\")\n",
    "    \n",
    "    def visualize(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        ae = Autoencoder(self.dims)\n",
    "        ae_model, encoder_model = ae.build()\n",
    "        input_ = ae_model.get_input_at(0)\n",
    "        noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_abs =tf.math.abs(noise)\n",
    "        noise_img = tf.add(input_, noise)\n",
    "        noise_img_clipped = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput = ae_model(noise_img_clipped)\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            ae_model.load_weights('./query-blinding-1-just-weights')\n",
    "            \n",
    "            feed_dict = {\n",
    "                input_: x_train\n",
    "            }\n",
    "            output, input_with_noise, noise_vis = sess.run([aeoutput, noise_img_clipped, noise_abs], feed_dict=feed_dict)\n",
    "            #output = np.array(output)\n",
    "#             print(output[0].shape)\n",
    "#             print(output[0][0].shape)\n",
    "            #print(output)\n",
    "            img = Image.fromarray((output[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeoutput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((input_with_noise[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeinput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((noise_vis[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('noise.png')\n",
    "            img.show()\n",
    "            #ae_model.save(\"saved_autoencoder_qb\")\n",
    "        \n",
    "    \n",
    "    def train(self, x_train, y_train,\n",
    "              lambda_1, batch_size, epochs, similar_ratio, margin,\n",
    "              weights_save_name, display_interval):\n",
    "        \"\"\"Train an autoencoder with standard mse loss + contrastive loss.\n",
    "        Arguments:\n",
    "            X_train {numpy.ndarray} -- feature vectors of the training data\n",
    "            y_train {numpy.ndarray} -- ground-truth labels of the training data\n",
    "            lambda_1 {float} -- balance factor for the autoencoder reconstruction loss and contrastive loss\n",
    "            batch_size {int} -- number of samples in each batch (note we only use **half of batch_size**\n",
    "                                from the training data).\n",
    "            epochs {int} -- No. of maximum epochs.\n",
    "            similar_ratio {float} -- ratio of similar samples, use 0.25 for now.\n",
    "            margin {float} -- the hyper-parameter m.\n",
    "            weights_save_name {str} -- file path to save the best weights files.\n",
    "            display_interval {int} -- print traning logs per {display_interval} epoches\n",
    "        \"\"\"\n",
    "        print(\"hello\")\n",
    "        if False:\n",
    "            logging.info('weights file exists, no need to train contrastive AE')\n",
    "        else:\n",
    "            tf.reset_default_graph()\n",
    "           \n",
    "            lambda_1_tensor = tf.placeholder(tf.float32)\n",
    "            ae = Autoencoder(self.dims)\n",
    "            ae_model, encoder_model = ae.build()\n",
    "\n",
    "            input_ = ae_model.get_input_at(0)\n",
    "            aclabels = tf.placeholder(tf.int32, [None, 1])\n",
    "            noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img = tf.add(input_, noise)\n",
    "            noise_img = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "            print(noise_img.shape)\n",
    "            noise_second = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img_second = tf.add(input_, noise_second)\n",
    "            noise_img_second = tf.clip_by_value(noise_img_second, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "\n",
    "            aeoutput = ae_model(noise_img)\n",
    "            aeoutput_second = ae_model(noise_img_second)\n",
    "            \n",
    "            model_dir = \"./\"\n",
    "            target_model2 = Load_Madry_Model(tf.Session(config=config), model_dir, noise_img, bias = 0.5, scale = 255)\n",
    "            target_model3 = Load_Madry_Model(tf.Session(config=config), model_dir, aeoutput, bias = 0.5, scale = 255)\n",
    "            \n",
    "            #print(target_model2.var_list)\n",
    "            output = tf.identity(target_model2.probs, name='my_output')\n",
    "            output2 = tf.identity(target_model3.probs, name='my_output2')\n",
    "            \n",
    "            aeoutput_mul = aeoutput*255\n",
    "            aeoutput_second_mul = aeoutput_second*255\n",
    "            l2_norm = tf.norm(aeoutput_second_mul - aeoutput_mul, ord='euclidean', axis=[-2,-1])\n",
    "            l2_norm_test = l2_norm\n",
    "            l2_norm = tf.pow(l2_norm, 2)\n",
    "            l2_norm = tf.math.minimum(l2_norm, 100)\n",
    "            \n",
    "            loss_crossentropy = tf.keras.losses.sparse_categorical_crossentropy(aclabels, output2)\n",
    "            loss_crossentropy = tf.reduce_mean(loss_crossentropy)\n",
    "            loss = loss_crossentropy - l2_norm\n",
    "            \n",
    "            \n",
    "            train_op = self.optimizer.minimize(loss, var_list=list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))\n",
    "\n",
    "            # Start training\n",
    "            with tf.Session(config=config) as sess:\n",
    "                loss_batch, aux_batch, ce_batch = [], [], []\n",
    "                contrastive_loss_batch, ae_loss_batch = [], []\n",
    "                \n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                target_model2.load_weights()\n",
    "                target_model3.load_weights()\n",
    "                min_loss = np.inf \n",
    "                \n",
    "                # epoch training loop\n",
    "                for epoch in range(100):\n",
    "                    epoch_time = time.time()\n",
    "                    # split data into batches\n",
    "                    batch_size = 30\n",
    "                    batch_count, batch_x, batch_y = batch_data(x_train, y_train, batch_size)\n",
    "                    batch_count = int(batch_count)\n",
    "                    print(\"BC: %d\" % batch_count)\n",
    "                    # batch training loop\n",
    "                    \n",
    "                    for b in range(batch_count):\n",
    "                        logging.debug(f'b: {b}')\n",
    "                        #add random noise to x_train (start with 0.01 first)\n",
    "                        feed_dict = {\n",
    "                            input_: batch_x[b*batch_size: b*batch_size+batch_size],\n",
    "                            lambda_1_tensor: lambda_1,\n",
    "                            aclabels: batch_y[b*batch_size: b*batch_size+batch_size],\n",
    "                        }\n",
    "                        \n",
    "                        labelled, labelled2,loss1,ae_loss1,loss_ce,_ = sess.run([output,output2,loss,l2_norm,loss_crossentropy,train_op], feed_dict=feed_dict)\n",
    "                        \n",
    "\n",
    "                        loss_batch.append(loss1)\n",
    "                        ae_loss_batch.append(ae_loss1)\n",
    "                        ce_batch.append(loss_ce)\n",
    "\n",
    "                    if math.isnan(np.mean(loss_batch)):\n",
    "                        logging.error('NaN value in loss')\n",
    "                    \n",
    "                    current_loss = np.mean(loss_batch)\n",
    "                    print(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "                                    f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "                                    f'ae {np.mean(ce_batch)} -- ' + \\\n",
    "                                    f'time {time.time() - epoch_time}')\n",
    "                print(\"saving weights\")\n",
    "                ae_model.save('./query-blinding-1-whole-model')\n",
    "                ae_model.save_weights('./query-blinding-1-just-weights')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "x_train = x_train[:100]\n",
    "y_train = y_train[:100]\n",
    "cae.train(x_train, y_train,\n",
    "                1e-1, 1, 1, 1, 1,\n",
    "                1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "x_train_vis = x_train[:1]\n",
    "cae.visualize(x_train_vis, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
