{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '1'\n",
    "from numpy.random import seed\n",
    "import random\n",
    "random.seed(1)\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "class Autoencoder(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 activation='relu',\n",
    "                 init='glorot_uniform',\n",
    "                 verbose=1):\n",
    "        '''\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "        The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        activation: activation, not applied to Input, last layer of the encoder, and Output layers\n",
    "        '''\n",
    "        self.dims = dims\n",
    "        self.act = activation\n",
    "        self.init = init\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"Fully connected auto-encoder model, symmetric.\n",
    "        return:\n",
    "            (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "        \"\"\"\n",
    "        input_img = Input(shape=(32, 32, 3))\n",
    "        \n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        self.encoded = encoded\n",
    "\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        ae = Model(inputs=input_img, outputs=decoded, name='AE')\n",
    "        encoder = Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "        return ae, encoder\n",
    "\n",
    "    def train_and_save(self, X,\n",
    "                       weights_save_name,\n",
    "                       lr=0.001,\n",
    "                       batch_size=32,\n",
    "                       epochs=250,\n",
    "                       loss='mse'):\n",
    "        if os.path.exists(weights_save_name):\n",
    "            logging.info('weights file exists, no need to train pure AE')\n",
    "        else:\n",
    "            logging.debug(f'AE train_and_save lr: {lr}')\n",
    "            logging.debug(f'AE train_and_save batch_size: {batch_size}')\n",
    "            logging.debug(f'AE train_and_save epochs: {epochs}')\n",
    "\n",
    "            verbose = self.verbose\n",
    "\n",
    "            autoencoder, encoder = self.build()\n",
    "\n",
    "            pretrain_optimizer = Adam(lr=lr)\n",
    "\n",
    "            autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "\n",
    "            utils.create_parent_folder(weights_save_name)\n",
    "\n",
    "            mcp_save = ModelCheckpoint(weights_save_name,\n",
    "                                    monitor='loss',\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=True,\n",
    "                                    verbose=verbose,\n",
    "                                    mode='min')\n",
    "\n",
    "            hist = autoencoder.fit(X, X,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=1,\n",
    "                                callbacks=[mcp_save, logger.LoggingCallback(logging.debug)])\n",
    "\n",
    "    def evaluate_quality(self, X_old, y_old, model_save_name):\n",
    "        if not os.path.exists(model_save_name):\n",
    "            self.train_and_save(X_old, model_save_name)\n",
    "\n",
    "        K.clear_session()\n",
    "        autoencoder, encoder = self.build()\n",
    "        encoder.load_weights(model_save_name, by_name=True)\n",
    "        logging.debug(f'Load weights from {model_save_name}')\n",
    "        latent = encoder.predict(X_old)\n",
    "\n",
    "        best_acc = 0\n",
    "        best_n_init = 10\n",
    "        num_classes = len(np.unique(y_old))\n",
    "        logging.debug(f'KMeans k = {num_classes}')\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        for n_init in range(10, 110, 10):\n",
    "            kmeans = KMeans(n_clusters=num_classes, n_init=n_init,\n",
    "                            random_state=42, n_jobs=-1)\n",
    "            y_pred = kmeans.fit_predict(latent)\n",
    "            acc = utils.get_cluster_acc(y_old, y_pred)\n",
    "            logging.debug(f'KMeans n_init: {n_init}, acc: {acc}')\n",
    "            if acc > best_acc:\n",
    "                best_n_init = best_n_init\n",
    "                best_acc = acc\n",
    "        logging.info(f'best accuracy of KMeans on latent data: {best_acc} with n_init {best_n_init}')\n",
    "        return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train[0])\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "x_train = x_train[:30000]\n",
    "y_train = y_train[:30000]\n",
    "x_test = x_test[:30000]\n",
    "y_test = y_test[:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x_train, y_train,batch_size):\n",
    "    batch_count = len(x_train)/batch_size\n",
    "    shuffler = np.random.permutation(len(x_train))\n",
    "    x_ret = x_train[shuffler]\n",
    "    y_ret = y_train[shuffler]\n",
    "    return batch_count, x_ret, y_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--path_dir PATH_DIR] [--type TYPE]\n",
      "                             [--epochs EPOCHS] [--trainable TRAINABLE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/chhabra4/.local/share/jupyter/runtime/kernel-f497e008-51de-4ee6-b7dc-9cca70a1e2f9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "import tensorflow as tf\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "if LooseVersion(keras.__version__) >= LooseVersion('2.0.0'):\n",
    "\tfrom keras.layers import Conv2D\n",
    "else:\n",
    "\tfrom keras.layers import Convolution2D\n",
    "\n",
    "# import argparse\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import os\n",
    "from setup_cifar import CIFAR\n",
    "# from tensorflow.python.platform import flags\n",
    "# FLAGS = flags.FLAGS\n",
    "IMAGE_ROWS = 32\n",
    "IMAGE_COLS = 32\n",
    "NUM_CHANNELS  = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def set_mnist_flags():\n",
    "\t# try:\n",
    "\t#     flags.DEFINE_integer('BATCH_SIZE', 64, 'Size of training batches')\n",
    "\t# except argparse.ArgumentError:\n",
    "\t#     pass\n",
    "\tflags.DEFINE_integer('BATCH_SIZE', 128, 'Size of training batches')\n",
    "\tflags.DEFINE_integer('NUM_CLASSES', 10, 'Number of classification classes')\n",
    "\tflags.DEFINE_integer('IMAGE_ROWS', 28, 'Input row dimension')\n",
    "\tflags.DEFINE_integer('IMAGE_COLS', 28, 'Input column dimension')\n",
    "\tflags.DEFINE_integer('NUM_CHANNELS', 1, 'Input depth dimension')\n",
    "\n",
    "\n",
    "def data_mnist(one_hot=True):\n",
    "\t\"\"\"\n",
    "\tPreprocess MNIST dataset\n",
    "\t\"\"\"\n",
    "\t# the data, shuffled and split between train and test sets\n",
    "\t(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\ty_train = y_train\n",
    "\n",
    "\n",
    "\tX_train = X_train.reshape(X_train.shape[0],\n",
    "\t\t\t\t\t\t\t  IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t  IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t  NUM_CHANNELS)\n",
    "\n",
    "\tX_test = X_test.reshape(X_test.shape[0],\n",
    "\t\t\t\t\t\t\tIMAGE_ROWS,\n",
    "\t\t\t\t\t\t\tIMAGE_COLS,\n",
    "\t\t\t\t\t\t\tNUM_CHANNELS)\n",
    "\n",
    "\tX_train = X_train.astype('float32')\n",
    "\tX_test = X_test.astype('float32')\n",
    "\tX_train /= 255 - 0.5\n",
    "\tX_test /= 255 -0.5\n",
    "\tprint('X_train shape:', X_train.shape)\n",
    "\tprint(X_train.shape[0], 'train samples')\n",
    "\tprint(X_test.shape[0], 'test samples')\n",
    "\n",
    "\tprint(\"Loaded MNIST test data.\")\n",
    "\n",
    "\tif one_hot:\n",
    "\t\t# convert class vectors to binary class matrices\n",
    "\t\ty_train = np_utils.to_categorical(y_train, NUM_CLASSES).astype(np.float32)\n",
    "\t\ty_test = np_utils.to_categorical(y_test, NUM_CLASSES).astype(np.float32)\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test\n",
    "\n",
    "# carlini model, use it as target model\n",
    "def modelA(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\t\n",
    "\tmodel.add(Conv2D(64, (3, 3),\n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(128, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(128, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelB(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dropout(0.2, input_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\tIMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\tNUM_CHANNELS)))\n",
    "\tmodel.add(Convolution2D(64, (8, 8),\n",
    "\t\t\t\t\t\t\tsubsample=(2, 2),\n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(128, (6, 6),\n",
    "\t\t\t\t\t\t\tsubsample=(2, 2),\n",
    "\t\t\t\t\t\t\tborder_mode='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(128, (5, 5),\n",
    "\t\t\t\t\t\t\tsubsample=(1, 1)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))  #14\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "\n",
    "def modelC(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(128, (3, 3),\n",
    "\t\t\t\t\t\t\tborder_mode='valid',\n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Convolution2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))  #14\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelD(input_ph):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding='same',\n",
    "\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(32, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Conv2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "def modelE(input_ph):\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(48, 3, 3, \n",
    "\t\t\t\t\t\t\tborder_mode='same', \n",
    "\t\t\t\t\t\t\tinput_shape=(IMAGE_ROWS,\n",
    "\t\t\t\t\t\t\t\t\t\t IMAGE_COLS,\n",
    "\t\t\t\t\t\t\t\t\t\t NUM_CHANNELS)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(48, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Convolution2D(96, 3, 3, \n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(96, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Convolution2D(192, 3, 3,\n",
    "\t\t\t\t\t\t\tborder_mode='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Convolution2D(192, 3, 3))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(NUM_CLASSES))\n",
    "\tlogits_tensor = model(input_ph)\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model, logits_tensor\n",
    "\n",
    "\n",
    "def model_cifar10(input_ph,type=1):\n",
    "\t\"\"\"\n",
    "\tDefines MNIST model using Keras sequential model\n",
    "\t\"\"\"\n",
    "\n",
    "\tmodels = [modelA, modelB, modelC, modelD, modelE]\n",
    "\tmodel = models[type]\n",
    "\treturn model(input_ph)\n",
    "\n",
    "\n",
    "def data_gen_mnist(X_train):\n",
    "\tdatagen = ImageDataGenerator()\n",
    "\n",
    "\tdatagen.fit(X_train)\n",
    "\treturn datagen\n",
    "\n",
    "# a unified framework for all mnist models\n",
    "\n",
    "\n",
    "def main(path_dir,trainable,type,epochs):\n",
    "\t# load the data first\n",
    "\tx = tf.placeholder(tf.float32, shape=(None, 32, 32, 3)) \n",
    "\tdata_augmentation = True\n",
    "\tdata = CIFAR()\n",
    "\tX_train, Y_train, X_test, Y_test = data.train_data, data.train_labels, data.test_data, data.test_labels\n",
    "\tmodel_names = ['modelA','modelB','modelC','modelD','modelE']\n",
    "\tmodel, logits_tensor = model_cifar10(input_ph = x, type = type)\n",
    "\tpath_dir = '' # put your file path for simple cifar10 models. THIS IS ONLY NEEDED WHEN TRAINING YOUR MODEL FROM SCRATCH\n",
    "\t# initiate RMSprop optimizer\n",
    "\t# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\topt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\t# Let's train the model using RMSprop\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\toptimizer=opt,\n",
    "\t\t\t\tmetrics=['accuracy'])\n",
    "\tbatch_size = 128\n",
    "\tif trainable:\n",
    "\t\tif not data_augmentation:\n",
    "\t\t\tprint('Not using data augmentation.')\n",
    "\t\t\tmodel.fit(X_train, Y_train,\n",
    "\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\tshuffle=True)\n",
    "\t\telse:\n",
    "\t\t\tprint('Using real-time data augmentation.')\n",
    "\t\t\t# This will do preprocessing and realtime data augmentation:\n",
    "\t\t\tdatagen = ImageDataGenerator(\n",
    "\t\t\t\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
    "\t\t\t\tsamplewise_center=False,  # set each sample mean to 0\n",
    "\t\t\t\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "\t\t\t\tsamplewise_std_normalization=False,  # divide each input by its std\n",
    "\t\t\t\tzca_whitening=False,  # apply ZCA whitening\n",
    "\t\t\t\tzca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "\t\t\t\trotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "\t\t\t\t# randomly shift images horizontally (fraction of total width)\n",
    "\t\t\t\twidth_shift_range=0.1,\n",
    "\t\t\t\t# randomly shift images vertically (fraction of total height)\n",
    "\t\t\t\theight_shift_range=0.1,\n",
    "\t\t\t\tshear_range=0.,  # set range for random shear\n",
    "\t\t\t\tzoom_range=0.,  # set range for random zoom\n",
    "\t\t\t\tchannel_shift_range=0.,  # set range for random channel shifts\n",
    "\t\t\t\t# set mode for filling points outside the input boundaries\n",
    "\t\t\t\tfill_mode='nearest',\n",
    "\t\t\t\tcval=0.,  # value used for fill_mode = \"constant\"\n",
    "\t\t\t\thorizontal_flip=True,  # randomly flip images\n",
    "\t\t\t\tvertical_flip=False,  # randomly flip images\n",
    "\t\t\t\t# set rescaling factor (applied before any other transformation)\n",
    "\t\t\t\trescale=None,\n",
    "\t\t\t\t# set function that will be applied on each input\n",
    "\t\t\t\tpreprocessing_function=None,\n",
    "\t\t\t\t# image data format, either \"channels_first\" or \"channels_last\"\n",
    "\t\t\t\tdata_format=None,\n",
    "\t\t\t\t# fraction of images reserved for validation (strictly between 0 and 1)\n",
    "\t\t\t\tvalidation_split=0.0)\n",
    "\n",
    "\t\t\t# Compute quantities required for feature-wise normalization\n",
    "\t\t\t# (std, mean, and principal components if ZCA whitening is applied).\n",
    "\t\t\tdatagen.fit(X_train)\n",
    "\n",
    "\t\t\t# Fit the model on the batches generated by datagen.flow().\n",
    "\t\t\tmodel.fit_generator(datagen.flow(X_train, Y_train,\n",
    "\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size),\n",
    "\t\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\t\t\t\tworkers=4)\n",
    "\t\t# save model and weights\n",
    "\t\tmodel_path = path_dir + model_names[type]+'.h5'\n",
    "\t\tmodel.save(model_path)\n",
    "\t\tprint('Saved trained model at %s ' % model_path)\n",
    "\telse:\n",
    "\t\tmodel = load_model(path_dir + model_names[type]+'.h5')\n",
    "\n",
    "\ttemp = np.argmax(model.predict(X_test),axis=1)\n",
    "\taccuracy = accuracy_score(np.argmax(Y_test,axis=1), temp)\n",
    "\tprint(\"oracle model accuracy:\",accuracy)\n",
    "\tscore = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "\t# Score trained model.\n",
    "\tscores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\tprint('Test loss:', scores[0])\n",
    "\tprint('Test accuracy:', scores[1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport argparse\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument(\"--path_dir\", type=str, default = \"model/cifar10/\",help=\"path to model\")\n",
    "\tparser.add_argument(\"--type\", type=int, help=\"model type\", default=1)\n",
    "\tparser.add_argument(\"--epochs\", type=int, default=50, help=\"number of epochs\")\n",
    "\tparser.add_argument(\"--trainable\", type=int, default = 1, help=\"decide if to train or directly load models\")\n",
    "\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\tmain(args.path_dir, args.trainable,args.type,args.epochs)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "class cifar10_models_simple1(object):\n",
    "\tdef __init__(self, sess, test_batch_size, type = 1,use_softmax = True, x = None, is_training=None,\\\n",
    "\t\t keep_prob=None,load_existing = False, model_name = 'modelA', loss = 'cw'):\n",
    "\t\tself.x = x\n",
    "\t\tself.sess = sess\n",
    "\t\tself.is_training = is_training\n",
    "\t\tself.keep_prob = keep_prob\n",
    "\t\tself.test_batch_size = test_batch_size\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.old_vars = set(tf.global_variables())\n",
    "\t\tif load_existing:\n",
    "\t\t\tsave_dir = 'CIFAR10_models/Normal_simple_models' # TODO: put your own ROOT directory of simple cifar10 models\n",
    "\t\t\tfilepath = os.path.join(save_dir, model_name+'.h5')\n",
    "\t\t\tfilepath = 'CIFAR10_models/Normal_simple_models/simple2/saved'\n",
    "\t\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\t\tmodel = load_model(filepath)\n",
    "\t\t\t\t#model._make_predict_function()\n",
    "\t\t\t\tself.model = model\n",
    "\t\t\t\tmodel = KerasModelWrapper(model)\n",
    "\t\t\t\tself.predictions = model.get_logits(self.x)\n",
    "\t\telse:\n",
    "\t\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\t\tmodel, preds = model_cifar10(input_ph = x, type = type)\n",
    "\t\t\t\tself.model = model\n",
    "\t\t\t\tself.predictions = preds\n",
    "\t\tself.new_vars = set(tf.global_variables())\n",
    "\t\tself.var_list = self.new_vars - self.old_vars\n",
    "\t\tself.probs = tf.nn.softmax(logits = self.predictions)\n",
    "\t\tself.eval_preds = tf.argmax(self.predictions, 1)\n",
    "\t\tself.y_target = tf.placeholder(tf.int64, shape=None) # tensor.shape (?,)\n",
    "\t\tself.eval_percent_adv = tf.equal(self.eval_preds, self.y_target) # one-to-one comparison\n",
    "\n",
    "\n",
    "\tdef load_weights(self):\n",
    "\t\t#print(mapping2)\n",
    "\t\twith tf.variable_scope('cifar10_model_simple', reuse=tf.AUTO_REUSE):\n",
    "\t\t\tsave_dir = 'CIFAR10_models/Normal_simple_models' # TODO: put your own ROOT directory of simple cifar10 models\n",
    "\t\t\tfilepath = 'CIFAR10_models/Normal_simple_models/simple2/saved'\n",
    "\t\t\tself.model.load_weights(filepath)\n",
    "\t\t\t#model._make_predict_function()\n",
    "\t\t\t#self.model = model\n",
    "\t\t\t#model = KerasModelWrapper(model)\n",
    "\t\t\t#self.predictions = model.get_logits(self.x)\n",
    "\t\t\t#self.probs = tf.nn.softmax(logits = self.predictions)\n",
    "\t\t\t#output = tf.identity(self.probs)\n",
    "\t\t\t#return output\n",
    "            \n",
    "\n",
    "\tdef save_everything(self):\n",
    "\t\th = self.model.save('CIFAR10_models/Normal_simple_models/simple2/saved')\n",
    "\t\tprint(h)\n",
    "\n",
    "\tdef calcu_acc(self,data,lab):\n",
    "\t\tbatch_size = self.test_batch_size\n",
    "\t\t#numpy operation to get prediction value\n",
    "\t\tcorr_preds = 0\n",
    "\t\tnum_batches = int(math.ceil(len(data) / batch_size))\n",
    "\t\tfor ibatch in range(num_batches):\n",
    "\t\t\tbstart = ibatch * batch_size\n",
    "\t\t\tbend = min(bstart + batch_size, len(data))\n",
    "\t\t\tdata_batch = data[bstart:bend,:]\n",
    "\t\t\tlab_batch = lab[bstart:bend]\n",
    "\t\t\t# acc calculation\n",
    "\t\t\tpreds = self.sess.run(self.predictions,feed_dict = {self.x:data_batch})\n",
    "\t\t\tcorr_preds += np.sum(np.argmax(lab_batch,axis = 1) == np.argmax(preds,axis = 1))\n",
    "\t\treturn corr_preds/len(data)\n",
    "\n",
    "\tdef predict_prob(self,data):\n",
    "\t\tbatch_size = self.test_batch_size\n",
    "\t\tprobs = []\n",
    "\t\tnum_batches = int(math.ceil(len(data) / batch_size))\n",
    "\t\tfor ibatch in range(num_batches):\n",
    "\t\t\tbstart = ibatch * batch_size\n",
    "\t\t\tbend = min(bstart + batch_size, len(data))\n",
    "\t\t\tdata_batch = data[bstart:bend,:]\n",
    "\t\t\t# acc calculation\n",
    "\t\t\tprob = self.sess.run(self.probs,feed_dict = {self.x:data_batch})\n",
    "\t\t\tprobs.extend(prob)\n",
    "\t\treturn np.array(probs) \n",
    "\tdef pred_class(self,data):\n",
    "\t\tpreds = self.predict_prob(data)\n",
    "\t\tlabels = np.argmax(preds,axis = 1)\n",
    "\t\treturn labels\n",
    "\n",
    "\tdef eval_adv(self, adv, target_class):\n",
    "\t\tfeed_dict = {self.x: adv, self.y_target: target_class}\n",
    "\t\tpadv = self.sess.run(self.eval_percent_adv, feed_dict=feed_dict)\n",
    "\t\treturn padv\n",
    "\n",
    "\tdef get_loss(self, data, labels,class_num = 10):\n",
    "\t\tif len(labels.shape) == 1:\n",
    "\t\t\tlabels = np_utils.to_categorical(labels, class_num)\n",
    "\t\tfeed_dict = {self.x: data, self.y: labels}\n",
    "\t\tloss_val = self.sess.run(self.loss, feed_dict = feed_dict)\n",
    "\t\treturn loss_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/chhabra4/anaconda3/envs/attack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[array([[1.01481592e-02, 9.02265951e-04, 5.56485504e-02, 9.61109921e-02,\n",
      "        2.54448038e-02, 1.95823777e-02, 7.71196842e-01, 3.82890739e-03,\n",
      "        1.62217598e-02, 9.15372162e-04],\n",
      "       [4.37106501e-04, 2.61574751e-03, 3.96338919e-06, 2.32017446e-05,\n",
      "        5.25345740e-08, 2.51373467e-06, 6.52457555e-09, 8.40115172e-06,\n",
      "        4.35338030e-03, 9.92555559e-01],\n",
      "       [7.46670961e-02, 6.41951337e-04, 5.83638554e-04, 7.27261358e-05,\n",
      "        1.77397320e-04, 2.29943780e-05, 3.02832450e-05, 5.57952677e-04,\n",
      "        8.39151721e-03, 9.14854348e-01],\n",
      "       [1.12772236e-08, 4.33854552e-09, 9.31090108e-06, 4.59966623e-06,\n",
      "        9.99934316e-01, 1.99548831e-05, 5.64594075e-06, 2.62103204e-05,\n",
      "        1.93373006e-09, 2.61356501e-08],\n",
      "       [5.88382045e-13, 9.99999881e-01, 6.88999316e-20, 1.76768447e-17,\n",
      "        1.41663105e-23, 1.12170966e-20, 1.13765096e-18, 1.25550869e-19,\n",
      "        5.92179300e-14, 1.50216039e-07],\n",
      "       [2.56637179e-07, 9.99785006e-01, 1.50327473e-09, 7.65537678e-08,\n",
      "        1.46114880e-12, 5.07963804e-09, 6.07130630e-08, 3.77747389e-09,\n",
      "        2.14597591e-07, 2.14322412e-04],\n",
      "       [2.86469944e-02, 7.09124142e-04, 8.55287552e-01, 5.07190675e-02,\n",
      "        4.20757234e-02, 4.22835723e-03, 3.68085108e-03, 2.01594201e-03,\n",
      "        3.96517804e-03, 8.67116917e-03],\n",
      "       [1.25700509e-11, 3.65119800e-13, 2.73264249e-07, 7.53354570e-08,\n",
      "        3.02892091e-04, 2.01757593e-05, 6.28855162e-11, 9.99676585e-01,\n",
      "        2.12237183e-14, 1.09619269e-12],\n",
      "       [5.94751000e-01, 3.86444190e-05, 4.75490000e-04, 3.92853399e-05,\n",
      "        1.95971234e-06, 5.70944167e-06, 1.82224485e-05, 8.93238175e-05,\n",
      "        4.04314131e-01, 2.66181014e-04],\n",
      "       [3.09840292e-02, 4.04109247e-04, 1.03425770e-03, 6.97886765e-01,\n",
      "        2.63548661e-02, 7.41125420e-02, 5.21921378e-04, 1.21317707e-01,\n",
      "        1.28292451e-02, 3.45544890e-02]], dtype=float32)]\n",
      "[[6 9 9 4 1 1 2 7 0 3]]\n",
      "[[1.01481592e-02 9.02265951e-04 5.56485504e-02 9.61109921e-02\n",
      "  2.54448038e-02 1.95823777e-02 7.71196842e-01 3.82890739e-03\n",
      "  1.62217598e-02 9.15372162e-04]\n",
      " [4.37106501e-04 2.61574751e-03 3.96338919e-06 2.32017446e-05\n",
      "  5.25345740e-08 2.51373467e-06 6.52457555e-09 8.40115172e-06\n",
      "  4.35338030e-03 9.92555559e-01]\n",
      " [7.46670961e-02 6.41951337e-04 5.83638554e-04 7.27261358e-05\n",
      "  1.77397320e-04 2.29943780e-05 3.02832450e-05 5.57952677e-04\n",
      "  8.39151721e-03 9.14854348e-01]\n",
      " [1.12772236e-08 4.33854552e-09 9.31090108e-06 4.59966623e-06\n",
      "  9.99934316e-01 1.99548831e-05 5.64594075e-06 2.62103204e-05\n",
      "  1.93373006e-09 2.61356501e-08]\n",
      " [5.88382045e-13 9.99999881e-01 6.88999316e-20 1.76768447e-17\n",
      "  1.41663105e-23 1.12170966e-20 1.13765096e-18 1.25550869e-19\n",
      "  5.92179300e-14 1.50216039e-07]\n",
      " [2.56637179e-07 9.99785006e-01 1.50327473e-09 7.65537678e-08\n",
      "  1.46114880e-12 5.07963804e-09 6.07130630e-08 3.77747389e-09\n",
      "  2.14597591e-07 2.14322412e-04]\n",
      " [2.86469944e-02 7.09124142e-04 8.55287552e-01 5.07190675e-02\n",
      "  4.20757234e-02 4.22835723e-03 3.68085108e-03 2.01594201e-03\n",
      "  3.96517804e-03 8.67116917e-03]\n",
      " [1.25700509e-11 3.65119800e-13 2.73264249e-07 7.53354570e-08\n",
      "  3.02892091e-04 2.01757593e-05 6.28855162e-11 9.99676585e-01\n",
      "  2.12237183e-14 1.09619269e-12]\n",
      " [5.94751000e-01 3.86444190e-05 4.75490000e-04 3.92853399e-05\n",
      "  1.95971234e-06 5.70944167e-06 1.82224485e-05 8.93238175e-05\n",
      "  4.04314131e-01 2.66181014e-04]\n",
      " [3.09840292e-02 4.04109247e-04 1.03425770e-03 6.97886765e-01\n",
      "  2.63548661e-02 7.41125420e-02 5.21921378e-04 1.21317707e-01\n",
      "  1.28292451e-02 3.45544890e-02]]\n",
      "[[1.01481592e-02 9.02265951e-04 5.56485504e-02 9.61109921e-02\n",
      "  2.54448038e-02 1.95823777e-02 7.71196842e-01 3.82890739e-03\n",
      "  1.62217598e-02 9.15372162e-04]\n",
      " [4.37106501e-04 2.61574751e-03 3.96338919e-06 2.32017446e-05\n",
      "  5.25345740e-08 2.51373467e-06 6.52457555e-09 8.40115172e-06\n",
      "  4.35338030e-03 9.92555559e-01]\n",
      " [7.46670961e-02 6.41951337e-04 5.83638554e-04 7.27261358e-05\n",
      "  1.77397320e-04 2.29943780e-05 3.02832450e-05 5.57952677e-04\n",
      "  8.39151721e-03 9.14854348e-01]\n",
      " [1.12772236e-08 4.33854552e-09 9.31090108e-06 4.59966623e-06\n",
      "  9.99934316e-01 1.99548831e-05 5.64594075e-06 2.62103204e-05\n",
      "  1.93373006e-09 2.61356501e-08]\n",
      " [5.88382045e-13 9.99999881e-01 6.88999316e-20 1.76768447e-17\n",
      "  1.41663105e-23 1.12170966e-20 1.13765096e-18 1.25550869e-19\n",
      "  5.92179300e-14 1.50216039e-07]\n",
      " [2.56637179e-07 9.99785006e-01 1.50327473e-09 7.65537678e-08\n",
      "  1.46114880e-12 5.07963804e-09 6.07130630e-08 3.77747389e-09\n",
      "  2.14597591e-07 2.14322412e-04]\n",
      " [2.86469944e-02 7.09124142e-04 8.55287552e-01 5.07190675e-02\n",
      "  4.20757234e-02 4.22835723e-03 3.68085108e-03 2.01594201e-03\n",
      "  3.96517804e-03 8.67116917e-03]\n",
      " [1.25700509e-11 3.65119800e-13 2.73264249e-07 7.53354570e-08\n",
      "  3.02892091e-04 2.01757593e-05 6.28855162e-11 9.99676585e-01\n",
      "  2.12237183e-14 1.09619269e-12]\n",
      " [5.94751000e-01 3.86444190e-05 4.75490000e-04 3.92853399e-05\n",
      "  1.95971234e-06 5.70944167e-06 1.82224485e-05 8.93238175e-05\n",
      "  4.04314131e-01 2.66181014e-04]\n",
      " [3.09840292e-02 4.04109247e-04 1.03425770e-03 6.97886765e-01\n",
      "  2.63548661e-02 7.41125420e-02 5.21921378e-04 1.21317707e-01\n",
      "  1.28292451e-02 3.45544890e-02]]\n",
      "[6 9 9 4 1 1 2 7 0 3 4 7 7 0 9 9 9 3 6 6]\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [7]\n",
      " [8]\n",
      " [3]\n",
      " [4]\n",
      " [7]\n",
      " [7]\n",
      " [2]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "class_num = 10\n",
    "image_size = 32\n",
    "num_channels = 3\n",
    "test_batch_size = 10\n",
    "x = tf.placeholder(tf.float32, shape=(None, image_size, image_size, num_channels))\n",
    "y = tf.placeholder(tf.float32, shape=(None, class_num))\n",
    "input_ = x\n",
    "\n",
    "target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = input_, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "\n",
    "output = tf.identity(target_model2.probs)\n",
    "# for i in tf.trainable_variables():\n",
    "#     mapping2[i.name[:-2]] = i\n",
    "#     #print(i.name)\n",
    "\n",
    "# print(mapping2)\n",
    "with sess as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    target_model2.load_weights()\n",
    "    #yb = sess.run([target_model2.predictions],feed_dict = {input_ : x_train[:10]})\n",
    "    #print(yb)\n",
    "    lb = sess.run([output],feed_dict = {input_ : x_train[:10]})\n",
    "    print(lb)\n",
    "    print(np.argmax(lb, axis=2))\n",
    "    yb,tb = sess.run([target_model2.probs,output],feed_dict = {input_ : x_train[:10]})\n",
    "    print(yb)\n",
    "    print(tb)\n",
    "    pro = target_model2.pred_class(x_train[:20])\n",
    "    print(pro)\n",
    "    print(y_train[:20])\n",
    "#     target_model3.load_weights()\n",
    "#     pro = target_model3.pred_class(x_train[20:30])\n",
    "#     print(pro)\n",
    "#     print(y_train[20:30])\n",
    "#     target_model2.save_everything()\n",
    "\n",
    "#tf.train.Saver(var_list=mapping).save(sess, 'CIFAR10_models/Normal_simple_models/simple/cp1')\n",
    "    #target_model2.save_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "from cifar10_simple_models import cifar10_models_simple\n",
    "\n",
    "tvars_vals = []\n",
    "\n",
    "class ContrastiveAE(object):\n",
    "    def __init__(self, optimizer, lr, dims = 1, verbose=1):\n",
    "        self.dims = dims\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.verbose = verbose\n",
    "        print(\"init\")\n",
    "    \n",
    "    def visualize(self, x_train, y_train):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        ae = Autoencoder(self.dims)\n",
    "        ae_model, encoder_model = ae.build()\n",
    "        input_ = ae_model.get_input_at(0)\n",
    "        noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "        noise_abs =tf.math.abs(noise)\n",
    "        noise_img = tf.add(input_, noise)\n",
    "        noise_img_clipped = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "        aeoutput = ae_model(noise_img_clipped)\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            ae_model.load_weights('./query-blinding-6-just-weights')\n",
    "            \n",
    "            feed_dict = {\n",
    "                input_: x_train\n",
    "            }\n",
    "            output, input_with_noise, noise_vis = sess.run([aeoutput, noise_img_clipped, noise_abs], feed_dict=feed_dict)\n",
    "            #output = np.array(output)\n",
    "#             print(output[0].shape)\n",
    "#             print(output[0][0].shape)\n",
    "            #print(output)\n",
    "            img = Image.fromarray((output[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeoutput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((input_with_noise[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('aeinput-noise.png')\n",
    "            img.show()\n",
    "            img = Image.fromarray((noise_vis[0]*255).astype('uint8'), 'RGB')\n",
    "            img.save('noise.png')\n",
    "            img.show()\n",
    "            #ae_model.save(\"saved_autoencoder_qb\")\n",
    "        \n",
    "    \n",
    "    def train(self, x_train, y_train,\n",
    "              lambda_1, batch_size, epochs, similar_ratio, margin,\n",
    "              weights_save_name, display_interval):\n",
    "        \"\"\"Train an autoencoder with standard mse loss + contrastive loss.\n",
    "        Arguments:\n",
    "            X_train {numpy.ndarray} -- feature vectors of the training data\n",
    "            y_train {numpy.ndarray} -- ground-truth labels of the training data\n",
    "            lambda_1 {float} -- balance factor for the autoencoder reconstruction loss and contrastive loss\n",
    "            batch_size {int} -- number of samples in each batch (note we only use **half of batch_size**\n",
    "                                from the training data).\n",
    "            epochs {int} -- No. of maximum epochs.\n",
    "            similar_ratio {float} -- ratio of similar samples, use 0.25 for now.\n",
    "            margin {float} -- the hyper-parameter m.\n",
    "            weights_save_name {str} -- file path to save the best weights files.\n",
    "            display_interval {int} -- print traning logs per {display_interval} epoches\n",
    "        \"\"\"\n",
    "        print(\"hello\")\n",
    "        if False:\n",
    "            logging.info('weights file exists, no need to train contrastive AE')\n",
    "        else:\n",
    "            tf.reset_default_graph()\n",
    "            \n",
    "            sess = tf.Session(config=config)\n",
    "            K.set_session(sess)\n",
    "           \n",
    "            lambda_1_tensor = tf.placeholder(tf.float32)\n",
    "            ae = Autoencoder(self.dims)\n",
    "            ae_model, encoder_model = ae.build()\n",
    "\n",
    "            input_ = ae_model.get_input_at(0)\n",
    "            aclabels = tf.placeholder(tf.int32, [None, 1])\n",
    "            noise = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img = tf.add(input_, noise)\n",
    "            noise_img = tf.clip_by_value(noise_img, clip_value_min=0, clip_value_max=1)\n",
    "            print(noise_img.shape)\n",
    "            noise_second = tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "            noise_img_second = tf.add(input_, noise_second)\n",
    "            noise_img_second = tf.clip_by_value(noise_img_second, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "\n",
    "            aeoutput = ae_model(noise_img)\n",
    "            aeoutput_second = ae_model(noise_img_second)\n",
    "            ae_loss = tf.keras.losses.MSE(noise_img, ae_model(noise_img)) # ae.out equals ae_model(input_)\n",
    "            ae_loss = tf.reduce_mean(ae_loss)\n",
    "            \n",
    "            model_dir = \"./\"\n",
    "#             target_model2 = Load_Madry_Model(tf.Session(config=config), model_dir, noise_img, bias = 0.5, scale = 255)\n",
    "#             target_model3 = Load_Madry_Model(tf.Session(config=config), model_dir, aeoutput, bias = 0.5, scale = 255)\n",
    "            t_m_o = tf.placeholder(tf.float32, shape=(None, 10)) \n",
    "            target_model2 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = noise_img, \n",
    "                                                              load_existing=False,model_name='modelA')\n",
    "            target_model3 = cifar10_models_simple1(sess,10, 0, use_softmax=True,x = aeoutput, \n",
    "                                                              load_existing=False,model_name='modelA')            \n",
    "            #print(target_model2.var_list)\n",
    "            output = tf.identity(target_model2.probs, name='my_output')\n",
    "            output2 = tf.identity(target_model3.probs, name='my_output2')\n",
    "            \n",
    "            aeoutput_mul = aeoutput*255\n",
    "            aeoutput_second_mul = aeoutput_second*255\n",
    "            l2_norm = tf.norm(aeoutput_second_mul - aeoutput_mul, ord='euclidean', axis=[-2,-1])\n",
    "            l2_norm_test = l2_norm\n",
    "            l2_norm = tf.pow(l2_norm, 2)\n",
    "            l2_norm = tf.math.minimum(l2_norm, 20)\n",
    "            \n",
    "            \n",
    "            loss_crossentropy = tf.keras.losses.sparse_categorical_crossentropy(aclabels, output2)\n",
    "            loss_crossentropy = tf.reduce_mean(loss_crossentropy)\n",
    "            loss = loss_crossentropy - l2_norm\n",
    "            \n",
    "            \n",
    "            train_op = self.optimizer.minimize(loss, var_list=list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))\n",
    "            print(list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))\n",
    "            # Start training\n",
    "            with sess as sess:\n",
    "                loss_batch, aux_batch, ce_batch = [], [], []\n",
    "                contrastive_loss_batch, ae_loss_batch = [], []\n",
    "                \n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                target_model2.load_weights()\n",
    "                target_model3.load_weights()\n",
    "                min_loss = np.inf \n",
    "                \n",
    "               \n",
    "                # epoch training loop\n",
    "                for epoch in range(250):\n",
    "                    epoch_time = time.time()\n",
    "                    # split data into batches\n",
    "                    batch_size = 100\n",
    "                    batch_count, batch_x, batch_y = batch_data(x_train, y_train, batch_size)\n",
    "                    batch_count = int(batch_count)\n",
    "                    print(\"BC: %d\" % batch_count)\n",
    "                    # batch training loop\n",
    "                    \n",
    "                    for b in range(batch_count):\n",
    "                        logging.debug(f'b: {b}')\n",
    "                        #add random noise to x_train (start with 0.01 first)\n",
    "                        feed_dict = {\n",
    "                            input_: batch_x[b*batch_size:b*batch_size + batch_size],\n",
    "                            lambda_1_tensor: lambda_1,\n",
    "                            aclabels: batch_y[b*batch_size:b*batch_size + batch_size],\n",
    "                        }\n",
    "#                         loss1, _, ae_loss1, \\\n",
    "#                             encoded1, labelled = sess.run([loss, train_op, ae_loss, ae.encoded, target_model2.model.softmax_pred], feed_dict=feed_dict)\n",
    "                        labelled, labelled2,loss1,ae_loss1,loss_ce,_ = sess.run([output,output2,loss,l2_norm,loss_crossentropy,train_op], feed_dict=feed_dict)\n",
    "                        #print(np.argmax(labelled, axis=1))\n",
    "                        #print(np.argmax(labelled2, axis=1))\n",
    "                        #print(labelled)\n",
    "                        #print(*y_train)\n",
    "                        \n",
    "                        loss_batch.append(loss1)\n",
    "                        ae_loss_batch.append(ae_loss1)\n",
    "                        ce_batch.append(loss_ce)\n",
    "\n",
    "                    if math.isnan(np.mean(loss_batch)):\n",
    "                        logging.error('NaN value in loss')\n",
    "                    \n",
    "                    current_loss = np.mean(loss_batch)\n",
    "                    print(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "                                    f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "                                    f'ae {np.mean(ce_batch)} -- ' + \\\n",
    "                                    f'time {time.time() - epoch_time}')\n",
    "                print(\"saving weights\")\n",
    "                ae_model.save('./query-blinding-6-whole-model')\n",
    "                ae_model.save_weights('./query-blinding-6-just-weights')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "30000\n",
      "hello\n",
      "(?, 32, 32, 3)\n",
      "[<tf.Variable 'batch_normalization_4/moving_variance:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 64, 16) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_5/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 32, 3) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/beta:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_3/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/moving_mean:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/moving_variance:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2d_4/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv2d_2/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'batch_normalization_4/moving_mean:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(16,) dtype=float32_ref>]\n",
      "BC: 80\n",
      "Epoch 0: loss -16.207250595092773 -- ae 19.280784606933594 -- ae 3.0735316276550293 -- time 2.4120309352874756\n",
      "BC: 80\n",
      "Epoch 1: loss -16.885969161987305 -- ae 19.637554168701172 -- ae 2.751584529876709 -- time 1.7519726753234863\n",
      "BC: 80\n",
      "Epoch 2: loss -17.162172317504883 -- ae 19.756149291992188 -- ae 2.5939724445343018 -- time 1.7507970333099365\n",
      "BC: 80\n",
      "Epoch 3: loss -17.33454704284668 -- ae 19.816381454467773 -- ae 2.4818313121795654 -- time 1.7583658695220947\n",
      "BC: 80\n",
      "Epoch 4: loss -17.47272300720215 -- ae 19.852689743041992 -- ae 2.3799614906311035 -- time 1.7897448539733887\n",
      "BC: 80\n",
      "Epoch 5: loss -17.580045700073242 -- ae 19.876955032348633 -- ae 2.2969040870666504 -- time 1.7810070514678955\n",
      "BC: 80\n",
      "Epoch 6: loss -17.663576126098633 -- ae 19.89430046081543 -- ae 2.230720281600952 -- time 1.7601444721221924\n",
      "BC: 80\n",
      "Epoch 7: loss -17.732824325561523 -- ae 19.907339096069336 -- ae 2.1745104789733887 -- time 1.777017593383789\n",
      "BC: 80\n",
      "Epoch 8: loss -17.789167404174805 -- ae 19.917552947998047 -- ae 2.128385543823242 -- time 1.7907371520996094\n",
      "BC: 80\n",
      "Epoch 9: loss -17.84092140197754 -- ae 19.92570686340332 -- ae 2.084779977798462 -- time 1.7684462070465088\n",
      "BC: 80\n",
      "Epoch 10: loss -17.886320114135742 -- ae 19.93242835998535 -- ae 2.0461018085479736 -- time 1.7801249027252197\n",
      "BC: 80\n",
      "Epoch 11: loss -17.922767639160156 -- ae 19.937950134277344 -- ae 2.0151777267456055 -- time 1.7802784442901611\n",
      "BC: 80\n",
      "Epoch 12: loss -17.956356048583984 -- ae 19.942691802978516 -- ae 1.9863319396972656 -- time 1.7792704105377197\n",
      "BC: 80\n",
      "Epoch 13: loss -17.9842529296875 -- ae 19.94673728942871 -- ae 1.9624792337417603 -- time 1.767228603363037\n",
      "BC: 80\n",
      "Epoch 14: loss -18.011154174804688 -- ae 19.950275421142578 -- ae 1.9391133785247803 -- time 1.7734858989715576\n",
      "BC: 80\n",
      "Epoch 15: loss -18.036537170410156 -- ae 19.953380584716797 -- ae 1.9168360233306885 -- time 1.807490348815918\n",
      "BC: 80\n",
      "Epoch 16: loss -18.05948257446289 -- ae 19.956096649169922 -- ae 1.8966039419174194 -- time 1.7677721977233887\n",
      "BC: 80\n",
      "Epoch 17: loss -18.08277130126953 -- ae 19.958515167236328 -- ae 1.875733494758606 -- time 1.775251865386963\n",
      "BC: 80\n",
      "Epoch 18: loss -18.103317260742188 -- ae 19.960683822631836 -- ae 1.8573538064956665 -- time 1.7840590476989746\n",
      "BC: 80\n",
      "Epoch 19: loss -18.123254776000977 -- ae 19.962635040283203 -- ae 1.839370846748352 -- time 1.7821645736694336\n",
      "BC: 80\n",
      "Epoch 20: loss -18.14185333251953 -- ae 19.964397430419922 -- ae 1.8225330114364624 -- time 1.784287929534912\n",
      "BC: 80\n",
      "Epoch 21: loss -18.15882682800293 -- ae 19.965999603271484 -- ae 1.8071653842926025 -- time 1.8067307472229004\n",
      "BC: 80\n",
      "Epoch 22: loss -18.175283432006836 -- ae 19.967477798461914 -- ae 1.792185664176941 -- time 1.7776820659637451\n",
      "BC: 80\n",
      "Epoch 23: loss -18.190549850463867 -- ae 19.968830108642578 -- ae 1.7782689332962036 -- time 1.777151107788086\n",
      "BC: 80\n",
      "Epoch 24: loss -18.204792022705078 -- ae 19.970069885253906 -- ae 1.7652709484100342 -- time 1.7757878303527832\n",
      "BC: 80\n",
      "Epoch 25: loss -18.218530654907227 -- ae 19.97121810913086 -- ae 1.7526805400848389 -- time 1.7835044860839844\n",
      "BC: 80\n",
      "Epoch 26: loss -18.23185920715332 -- ae 19.972280502319336 -- ae 1.7404171228408813 -- time 1.7934250831604004\n",
      "BC: 80\n",
      "Epoch 27: loss -18.243640899658203 -- ae 19.973264694213867 -- ae 1.7296160459518433 -- time 1.803140640258789\n",
      "BC: 80\n",
      "Epoch 28: loss -18.254329681396484 -- ae 19.974180221557617 -- ae 1.7198410034179688 -- time 1.8315205574035645\n",
      "BC: 80\n",
      "Epoch 29: loss -18.266632080078125 -- ae 19.975040435791016 -- ae 1.708400011062622 -- time 1.7760722637176514\n",
      "BC: 80\n",
      "Epoch 30: loss -18.277620315551758 -- ae 19.9758358001709 -- ae 1.6982057094573975 -- time 1.7890310287475586\n",
      "BC: 80\n",
      "Epoch 31: loss -18.28839874267578 -- ae 19.976587295532227 -- ae 1.6881805658340454 -- time 1.8015954494476318\n",
      "BC: 80\n",
      "Epoch 32: loss -18.29725456237793 -- ae 19.977291107177734 -- ae 1.6800322532653809 -- time 1.9068958759307861\n",
      "BC: 80\n",
      "Epoch 33: loss -18.306903839111328 -- ae 19.97795867919922 -- ae 1.671046495437622 -- time 1.8481123447418213\n",
      "BC: 80\n",
      "Epoch 34: loss -18.316585540771484 -- ae 19.97859001159668 -- ae 1.6619948148727417 -- time 1.860337495803833\n",
      "BC: 80\n",
      "Epoch 35: loss -18.325265884399414 -- ae 19.979183197021484 -- ae 1.6539065837860107 -- time 2.0710318088531494\n",
      "BC: 80\n",
      "Epoch 36: loss -18.334522247314453 -- ae 19.979745864868164 -- ae 1.6452105045318604 -- time 1.855165958404541\n",
      "BC: 80\n",
      "Epoch 37: loss -18.343448638916016 -- ae 19.98027801513672 -- ae 1.6368170976638794 -- time 1.860720157623291\n",
      "BC: 80\n",
      "Epoch 38: loss -18.351640701293945 -- ae 19.98078155517578 -- ae 1.6291290521621704 -- time 1.9558227062225342\n",
      "BC: 80\n",
      "Epoch 39: loss -18.35986328125 -- ae 19.981260299682617 -- ae 1.6213840246200562 -- time 1.9945800304412842\n",
      "BC: 80\n",
      "Epoch 40: loss -18.368213653564453 -- ae 19.981718063354492 -- ae 1.6134878396987915 -- time 2.0011048316955566\n",
      "BC: 80\n",
      "Epoch 41: loss -18.376665115356445 -- ae 19.98215103149414 -- ae 1.6054679155349731 -- time 1.9966938495635986\n",
      "BC: 80\n",
      "Epoch 42: loss -18.38475227355957 -- ae 19.982563018798828 -- ae 1.5977959632873535 -- time 1.918030023574829\n",
      "BC: 80\n",
      "Epoch 43: loss -18.392261505126953 -- ae 19.98295783996582 -- ae 1.5906857252120972 -- time 2.0098636150360107\n",
      "BC: 80\n",
      "Epoch 44: loss -18.399839401245117 -- ae 19.983335494995117 -- ae 1.5834884643554688 -- time 1.9590368270874023\n",
      "BC: 80\n",
      "Epoch 45: loss -18.407066345214844 -- ae 19.98369789123535 -- ae 1.576626181602478 -- time 2.00789475440979\n",
      "BC: 80\n",
      "Epoch 46: loss -18.41439437866211 -- ae 19.98404312133789 -- ae 1.5696442127227783 -- time 1.9705219268798828\n",
      "BC: 80\n",
      "Epoch 47: loss -18.421449661254883 -- ae 19.984375 -- ae 1.5629206895828247 -- time 1.942695140838623\n",
      "BC: 80\n",
      "Epoch 48: loss -18.42755699157715 -- ae 19.984691619873047 -- ae 1.5571314096450806 -- time 1.9623332023620605\n",
      "BC: 80\n",
      "Epoch 49: loss -18.434354782104492 -- ae 19.984996795654297 -- ae 1.5506349802017212 -- time 1.9930634498596191\n",
      "BC: 80\n",
      "Epoch 50: loss -18.4409122467041 -- ae 19.985292434692383 -- ae 1.5443737506866455 -- time 2.0350849628448486\n",
      "BC: 80\n",
      "Epoch 51: loss -18.446958541870117 -- ae 19.98557472229004 -- ae 1.5386080741882324 -- time 2.010326623916626\n",
      "BC: 80\n",
      "Epoch 52: loss -18.452917098999023 -- ae 19.985843658447266 -- ae 1.5329171419143677 -- time 2.020554780960083\n",
      "BC: 80\n",
      "Epoch 53: loss -18.458728790283203 -- ae 19.986106872558594 -- ae 1.5273672342300415 -- time 2.0208919048309326\n",
      "BC: 80\n",
      "Epoch 54: loss -18.46381950378418 -- ae 19.986358642578125 -- ae 1.522527813911438 -- time 2.0501937866210938\n",
      "BC: 80\n",
      "Epoch 55: loss -18.469526290893555 -- ae 19.986602783203125 -- ae 1.5170661211013794 -- time 2.014887571334839\n",
      "BC: 80\n",
      "Epoch 56: loss -18.475109100341797 -- ae 19.98683738708496 -- ae 1.511721134185791 -- time 1.9653217792510986\n",
      "BC: 80\n",
      "Epoch 57: loss -18.4803409576416 -- ae 19.987064361572266 -- ae 1.5067188739776611 -- time 2.0068180561065674\n",
      "BC: 80\n",
      "Epoch 58: loss -18.4858455657959 -- ae 19.98728370666504 -- ae 1.501432180404663 -- time 2.010647773742676\n",
      "BC: 80\n",
      "Epoch 59: loss -18.491682052612305 -- ae 19.987491607666016 -- ae 1.495803713798523 -- time 2.0406031608581543\n",
      "BC: 80\n",
      "Epoch 60: loss -18.49750328063965 -- ae 19.98769760131836 -- ae 1.4901845455169678 -- time 2.0935187339782715\n",
      "BC: 80\n",
      "Epoch 61: loss -18.502546310424805 -- ae 19.98789405822754 -- ae 1.4853392839431763 -- time 2.109147548675537\n",
      "BC: 80\n",
      "Epoch 62: loss -18.5076847076416 -- ae 19.98808479309082 -- ae 1.4803937673568726 -- time 2.069876194000244\n",
      "BC: 80\n",
      "Epoch 63: loss -18.51325798034668 -- ae 19.988269805908203 -- ae 1.47500741481781 -- time 2.133016347885132\n",
      "BC: 80\n",
      "Epoch 64: loss -18.518329620361328 -- ae 19.988447189331055 -- ae 1.4701093435287476 -- time 2.1455419063568115\n",
      "BC: 80\n",
      "Epoch 65: loss -18.52330207824707 -- ae 19.988622665405273 -- ae 1.4653093814849854 -- time 2.056244134902954\n",
      "BC: 80\n",
      "Epoch 66: loss -18.528614044189453 -- ae 19.98879051208496 -- ae 1.4601646661758423 -- time 2.1159186363220215\n",
      "BC: 80\n",
      "Epoch 67: loss -18.533203125 -- ae 19.988956451416016 -- ae 1.4557452201843262 -- time 2.059856414794922\n",
      "BC: 80\n",
      "Epoch 68: loss -18.53790283203125 -- ae 19.98911476135254 -- ae 1.4512001276016235 -- time 2.038517475128174\n",
      "BC: 80\n",
      "Epoch 69: loss -18.54254913330078 -- ae 19.989269256591797 -- ae 1.4467068910598755 -- time 2.259647846221924\n",
      "BC: 80\n",
      "Epoch 70: loss -18.547435760498047 -- ae 19.98941993713379 -- ae 1.4419671297073364 -- time 2.0421690940856934\n",
      "BC: 80\n",
      "Epoch 71: loss -18.551410675048828 -- ae 19.989566802978516 -- ae 1.4381333589553833 -- time 2.0495803356170654\n",
      "BC: 80\n",
      "Epoch 72: loss -18.55617904663086 -- ae 19.989709854125977 -- ae 1.4335076808929443 -- time 2.0601696968078613\n",
      "BC: 80\n",
      "Epoch 73: loss -18.56066131591797 -- ae 19.98984718322754 -- ae 1.4291642904281616 -- time 2.099846601486206\n",
      "BC: 80\n",
      "Epoch 74: loss -18.565065383911133 -- ae 19.98998260498047 -- ae 1.4248934984207153 -- time 2.10770583152771\n",
      "BC: 80\n",
      "Epoch 75: loss -18.569656372070312 -- ae 19.990114212036133 -- ae 1.4204342365264893 -- time 2.0898494720458984\n",
      "BC: 80\n",
      "Epoch 76: loss -18.57423973083496 -- ae 19.99024200439453 -- ae 1.4159762859344482 -- time 2.0917022228240967\n",
      "BC: 80\n",
      "Epoch 77: loss -18.578815460205078 -- ae 19.990367889404297 -- ae 1.4115246534347534 -- time 1.9814653396606445\n",
      "BC: 80\n",
      "Epoch 78: loss -18.58291244506836 -- ae 19.990488052368164 -- ae 1.407546877861023 -- time 1.9633758068084717\n",
      "BC: 80\n",
      "Epoch 79: loss -18.5872745513916 -- ae 19.99060821533203 -- ae 1.403297781944275 -- time 1.9851443767547607\n",
      "BC: 80\n",
      "Epoch 80: loss -18.59099006652832 -- ae 19.990724563598633 -- ae 1.3997019529342651 -- time 1.9596140384674072\n",
      "BC: 80\n",
      "Epoch 81: loss -18.595033645629883 -- ae 19.990835189819336 -- ae 1.3957735300064087 -- time 1.9846503734588623\n",
      "BC: 80\n",
      "Epoch 82: loss -18.599258422851562 -- ae 19.99094581604004 -- ae 1.3916574716567993 -- time 1.9843626022338867\n",
      "BC: 80\n",
      "Epoch 83: loss -18.6030216217041 -- ae 19.991052627563477 -- ae 1.3880025148391724 -- time 1.9940409660339355\n",
      "BC: 80\n",
      "Epoch 84: loss -18.60687828063965 -- ae 19.99115753173828 -- ae 1.3842512369155884 -- time 2.0110361576080322\n",
      "BC: 80\n",
      "Epoch 85: loss -18.61095428466797 -- ae 19.991260528564453 -- ae 1.3802748918533325 -- time 2.0298943519592285\n",
      "BC: 80\n",
      "Epoch 86: loss -18.61469268798828 -- ae 19.99135971069336 -- ae 1.3766344785690308 -- time 1.9997708797454834\n",
      "BC: 80\n",
      "Epoch 87: loss -18.618249893188477 -- ae 19.991455078125 -- ae 1.3731743097305298 -- time 1.9752652645111084\n",
      "BC: 80\n",
      "Epoch 88: loss -18.621816635131836 -- ae 19.99155044555664 -- ae 1.3697007894515991 -- time 2.013685703277588\n",
      "BC: 80\n",
      "Epoch 89: loss -18.62540626525879 -- ae 19.99164390563965 -- ae 1.3662046194076538 -- time 2.0001556873321533\n",
      "BC: 80\n",
      "Epoch 90: loss -18.629140853881836 -- ae 19.991735458374023 -- ae 1.3625627756118774 -- time 2.001887798309326\n",
      "BC: 80\n",
      "Epoch 91: loss -18.632596969604492 -- ae 19.9918270111084 -- ae 1.359196424484253 -- time 1.9835331439971924\n",
      "BC: 80\n",
      "Epoch 92: loss -18.636032104492188 -- ae 19.991914749145508 -- ae 1.3558465242385864 -- time 2.0338170528411865\n",
      "BC: 80\n",
      "Epoch 93: loss -18.63933563232422 -- ae 19.99199867248535 -- ae 1.3526276350021362 -- time 2.020256280899048\n",
      "BC: 80\n",
      "Epoch 94: loss -18.642967224121094 -- ae 19.992082595825195 -- ae 1.349081039428711 -- time 2.0147640705108643\n",
      "BC: 80\n",
      "Epoch 95: loss -18.646577835083008 -- ae 19.992164611816406 -- ae 1.345550775527954 -- time 2.058336019515991\n",
      "BC: 80\n",
      "Epoch 96: loss -18.650197982788086 -- ae 19.992246627807617 -- ae 1.342012643814087 -- time 2.050631046295166\n",
      "BC: 80\n",
      "Epoch 97: loss -18.653493881225586 -- ae 19.992324829101562 -- ae 1.3387993574142456 -- time 2.020691156387329\n",
      "BC: 80\n",
      "Epoch 98: loss -18.656808853149414 -- ae 19.992403030395508 -- ae 1.3355590105056763 -- time 2.012155294418335\n",
      "BC: 80\n",
      "Epoch 99: loss -18.660242080688477 -- ae 19.99247932434082 -- ae 1.332205057144165 -- time 2.0042576789855957\n",
      "BC: 80\n",
      "Epoch 100: loss -18.663646697998047 -- ae 19.992551803588867 -- ae 1.328870415687561 -- time 2.028730869293213\n",
      "BC: 80\n",
      "Epoch 101: loss -18.666696548461914 -- ae 19.992624282836914 -- ae 1.325891375541687 -- time 2.0312187671661377\n",
      "BC: 80\n",
      "Epoch 102: loss -18.669857025146484 -- ae 19.992694854736328 -- ae 1.3228012323379517 -- time 2.05535626411438\n",
      "BC: 80\n",
      "Epoch 103: loss -18.672975540161133 -- ae 19.992765426635742 -- ae 1.3197540044784546 -- time 2.0508813858032227\n",
      "BC: 80\n",
      "Epoch 104: loss -18.675891876220703 -- ae 19.992834091186523 -- ae 1.316906213760376 -- time 2.0335614681243896\n",
      "BC: 80\n",
      "Epoch 105: loss -18.678808212280273 -- ae 19.992900848388672 -- ae 1.3140579462051392 -- time 2.0515522956848145\n",
      "BC: 80\n",
      "Epoch 106: loss -18.68169593811035 -- ae 19.99296760559082 -- ae 1.3112363815307617 -- time 2.0676989555358887\n",
      "BC: 80\n",
      "Epoch 107: loss -18.684892654418945 -- ae 19.993032455444336 -- ae 1.308104395866394 -- time 2.033395528793335\n",
      "BC: 80\n",
      "Epoch 108: loss -18.687639236450195 -- ae 19.99309539794922 -- ae 1.3054211139678955 -- time 2.042651891708374\n",
      "BC: 80\n",
      "Epoch 109: loss -18.690593719482422 -- ae 19.9931583404541 -- ae 1.3025321960449219 -- time 2.0449278354644775\n",
      "BC: 80\n",
      "Epoch 110: loss -18.69341278076172 -- ae 19.993221282958984 -- ae 1.299772024154663 -- time 2.0364463329315186\n",
      "BC: 80\n",
      "Epoch 111: loss -18.69618034362793 -- ae 19.9932804107666 -- ae 1.2970672845840454 -- time 2.071972131729126\n",
      "BC: 80\n",
      "Epoch 112: loss -18.699047088623047 -- ae 19.99334144592285 -- ae 1.2942615747451782 -- time 2.0404558181762695\n",
      "BC: 80\n",
      "Epoch 113: loss -18.702117919921875 -- ae 19.993396759033203 -- ae 1.291244387626648 -- time 2.0726304054260254\n",
      "BC: 80\n",
      "Epoch 114: loss -18.705141067504883 -- ae 19.993453979492188 -- ae 1.288282036781311 -- time 2.0758841037750244\n",
      "BC: 80\n",
      "Epoch 115: loss -18.7080135345459 -- ae 19.993511199951172 -- ae 1.2854673862457275 -- time 2.056670665740967\n",
      "BC: 80\n",
      "Epoch 116: loss -18.71074867248535 -- ae 19.993566513061523 -- ae 1.282787561416626 -- time 2.038376808166504\n",
      "BC: 80\n",
      "Epoch 117: loss -18.71368980407715 -- ae 19.993619918823242 -- ae 1.2798963785171509 -- time 2.073021173477173\n",
      "BC: 80\n",
      "Epoch 118: loss -18.716623306274414 -- ae 19.993675231933594 -- ae 1.2770142555236816 -- time 2.069108724594116\n",
      "BC: 80\n",
      "Epoch 119: loss -18.719398498535156 -- ae 19.99372673034668 -- ae 1.2742875814437866 -- time 2.0409231185913086\n",
      "BC: 80\n",
      "Epoch 120: loss -18.722177505493164 -- ae 19.993778228759766 -- ae 1.2715601921081543 -- time 2.0546345710754395\n",
      "BC: 80\n",
      "Epoch 121: loss -18.724889755249023 -- ae 19.99382972717285 -- ae 1.268900752067566 -- time 2.0588741302490234\n",
      "BC: 80\n",
      "Epoch 122: loss -18.7276554107666 -- ae 19.993879318237305 -- ae 1.2661858797073364 -- time 2.07539963722229\n",
      "BC: 80\n",
      "Epoch 123: loss -18.730411529541016 -- ae 19.993928909301758 -- ae 1.2634800672531128 -- time 2.070007562637329\n",
      "BC: 80\n",
      "Epoch 124: loss -18.73312759399414 -- ae 19.99397850036621 -- ae 1.2608115673065186 -- time 2.0916619300842285\n",
      "BC: 80\n",
      "Epoch 125: loss -18.73566246032715 -- ae 19.99402618408203 -- ae 1.2583227157592773 -- time 2.0827255249023438\n",
      "BC: 80\n",
      "Epoch 126: loss -18.738374710083008 -- ae 19.99407196044922 -- ae 1.2556586265563965 -- time 2.1081740856170654\n",
      "BC: 80\n",
      "Epoch 127: loss -18.740928649902344 -- ae 19.99411964416504 -- ae 1.2531564235687256 -- time 2.081312656402588\n",
      "BC: 80\n",
      "Epoch 128: loss -18.74370002746582 -- ae 19.994165420532227 -- ae 1.2504315376281738 -- time 2.081806182861328\n",
      "BC: 80\n",
      "Epoch 129: loss -18.74590301513672 -- ae 19.99420928955078 -- ae 1.2482746839523315 -- time 2.0897347927093506\n",
      "BC: 80\n",
      "Epoch 130: loss -18.748388290405273 -- ae 19.994253158569336 -- ae 1.2458382844924927 -- time 2.0723419189453125\n",
      "BC: 80\n",
      "Epoch 131: loss -18.750917434692383 -- ae 19.99429702758789 -- ae 1.243360161781311 -- time 2.1178622245788574\n",
      "BC: 80\n",
      "Epoch 132: loss -18.753429412841797 -- ae 19.994340896606445 -- ae 1.2408894300460815 -- time 2.1091115474700928\n",
      "BC: 80\n",
      "Epoch 133: loss -18.755979537963867 -- ae 19.994382858276367 -- ae 1.2383825778961182 -- time 2.1295292377471924\n",
      "BC: 80\n",
      "Epoch 134: loss -18.758501052856445 -- ae 19.99442481994629 -- ae 1.2358973026275635 -- time 2.1074514389038086\n",
      "BC: 80\n",
      "Epoch 135: loss -18.760892868041992 -- ae 19.994464874267578 -- ae 1.233544945716858 -- time 2.1160929203033447\n",
      "BC: 80\n",
      "Epoch 136: loss -18.76336669921875 -- ae 19.994504928588867 -- ae 1.2311108112335205 -- time 2.358879804611206\n",
      "BC: 80\n",
      "Epoch 137: loss -18.76551628112793 -- ae 19.994544982910156 -- ae 1.2290058135986328 -- time 2.100719451904297\n",
      "BC: 80\n",
      "Epoch 138: loss -18.767934799194336 -- ae 19.994585037231445 -- ae 1.226630449295044 -- time 2.1039912700653076\n",
      "BC: 80\n",
      "Epoch 139: loss -18.770334243774414 -- ae 19.9946231842041 -- ae 1.2242618799209595 -- time 2.245709180831909\n",
      "BC: 80\n",
      "Epoch 140: loss -18.772624969482422 -- ae 19.994661331176758 -- ae 1.2220062017440796 -- time 2.2385902404785156\n",
      "BC: 80\n",
      "Epoch 141: loss -18.774810791015625 -- ae 19.994699478149414 -- ae 1.2198545932769775 -- time 2.213838815689087\n",
      "BC: 80\n",
      "Epoch 142: loss -18.77718162536621 -- ae 19.994735717773438 -- ae 1.2175216674804688 -- time 2.2382659912109375\n",
      "BC: 80\n",
      "Epoch 143: loss -18.779470443725586 -- ae 19.99477195739746 -- ae 1.215268611907959 -- time 2.216782808303833\n",
      "BC: 80\n",
      "Epoch 144: loss -18.781644821166992 -- ae 19.994808197021484 -- ae 1.2131328582763672 -- time 2.2283265590667725\n",
      "BC: 80\n",
      "Epoch 145: loss -18.78390884399414 -- ae 19.994844436645508 -- ae 1.2109018564224243 -- time 2.243234634399414\n",
      "BC: 80\n",
      "Epoch 146: loss -18.786148071289062 -- ae 19.9948787689209 -- ae 1.2086955308914185 -- time 2.248586654663086\n",
      "BC: 80\n",
      "Epoch 147: loss -18.78840446472168 -- ae 19.99491310119629 -- ae 1.2064775228500366 -- time 2.2855942249298096\n",
      "BC: 80\n",
      "Epoch 148: loss -18.790468215942383 -- ae 19.99494743347168 -- ae 1.2044461965560913 -- time 2.254997491836548\n",
      "BC: 80\n",
      "Epoch 149: loss -18.792652130126953 -- ae 19.99498176574707 -- ae 1.202297568321228 -- time 2.3046607971191406\n",
      "BC: 80\n",
      "Epoch 150: loss -18.794830322265625 -- ae 19.995014190673828 -- ae 1.2001527547836304 -- time 2.2467875480651855\n",
      "BC: 80\n",
      "Epoch 151: loss -18.79705810546875 -- ae 19.99504852294922 -- ae 1.1979568004608154 -- time 2.2606492042541504\n",
      "BC: 80\n",
      "Epoch 152: loss -18.799091339111328 -- ae 19.995080947875977 -- ae 1.195955514907837 -- time 2.2325799465179443\n",
      "BC: 80\n",
      "Epoch 153: loss -18.801231384277344 -- ae 19.9951114654541 -- ae 1.193852424621582 -- time 2.2396888732910156\n",
      "BC: 80\n",
      "Epoch 154: loss -18.803268432617188 -- ae 19.99514389038086 -- ae 1.1918504238128662 -- time 2.3296022415161133\n",
      "BC: 80\n",
      "Epoch 155: loss -18.805309295654297 -- ae 19.995174407958984 -- ae 1.1898455619812012 -- time 2.2521331310272217\n",
      "BC: 80\n",
      "Epoch 156: loss -18.807374954223633 -- ae 19.99520492553711 -- ae 1.1878061294555664 -- time 2.201885938644409\n",
      "BC: 80\n",
      "Epoch 157: loss -18.809349060058594 -- ae 19.995235443115234 -- ae 1.1858596801757812 -- time 2.224987030029297\n",
      "BC: 80\n",
      "Epoch 158: loss -18.811229705810547 -- ae 19.99526596069336 -- ae 1.184009313583374 -- time 2.292301893234253\n",
      "BC: 80\n",
      "Epoch 159: loss -18.81328010559082 -- ae 19.99529457092285 -- ae 1.1819863319396973 -- time 2.3454248905181885\n",
      "BC: 80\n",
      "Epoch 160: loss -18.815231323242188 -- ae 19.995325088500977 -- ae 1.1800650358200073 -- time 2.3702735900878906\n",
      "BC: 80\n",
      "Epoch 161: loss -18.81694793701172 -- ae 19.99535369873047 -- ae 1.1783781051635742 -- time 2.2667367458343506\n",
      "BC: 80\n",
      "Epoch 162: loss -18.818986892700195 -- ae 19.99538230895996 -- ae 1.1763683557510376 -- time 2.278581142425537\n",
      "BC: 80\n",
      "Epoch 163: loss -18.821002960205078 -- ae 19.995410919189453 -- ae 1.1743793487548828 -- time 2.3239798545837402\n",
      "BC: 80\n",
      "Epoch 164: loss -18.822921752929688 -- ae 19.995437622070312 -- ae 1.1724897623062134 -- time 2.255406379699707\n",
      "BC: 80\n",
      "Epoch 165: loss -18.824743270874023 -- ae 19.995466232299805 -- ae 1.170691728591919 -- time 2.3237199783325195\n",
      "BC: 80\n",
      "Epoch 166: loss -18.826641082763672 -- ae 19.995492935180664 -- ae 1.1688200235366821 -- time 2.2975096702575684\n",
      "BC: 80\n",
      "Epoch 167: loss -18.828615188598633 -- ae 19.995519638061523 -- ae 1.1668721437454224 -- time 2.3544602394104004\n",
      "BC: 80\n",
      "Epoch 168: loss -18.830448150634766 -- ae 19.995546340942383 -- ae 1.1650710105895996 -- time 2.417020082473755\n",
      "BC: 80\n",
      "Epoch 169: loss -18.832260131835938 -- ae 19.99557113647461 -- ae 1.1632850170135498 -- time 2.2751271724700928\n",
      "BC: 80\n",
      "Epoch 170: loss -18.83418846130371 -- ae 19.99559783935547 -- ae 1.1613829135894775 -- time 2.2325265407562256\n",
      "BC: 80\n",
      "Epoch 171: loss -18.8360652923584 -- ae 19.995622634887695 -- ae 1.1595313549041748 -- time 2.2695841789245605\n",
      "BC: 80\n",
      "Epoch 172: loss -18.837923049926758 -- ae 19.995649337768555 -- ae 1.157699465751648 -- time 2.2371888160705566\n",
      "BC: 80\n",
      "Epoch 173: loss -18.839719772338867 -- ae 19.99567413330078 -- ae 1.1559303998947144 -- time 2.2557308673858643\n",
      "BC: 80\n",
      "Epoch 174: loss -18.841516494750977 -- ae 19.995698928833008 -- ae 1.1541590690612793 -- time 2.2614357471466064\n",
      "BC: 80\n",
      "Epoch 175: loss -18.843290328979492 -- ae 19.995723724365234 -- ae 1.152410864830017 -- time 2.2339348793029785\n",
      "BC: 80\n",
      "Epoch 176: loss -18.84519386291504 -- ae 19.995746612548828 -- ae 1.1505320072174072 -- time 2.3001930713653564\n",
      "BC: 80\n",
      "Epoch 177: loss -18.847013473510742 -- ae 19.995771408081055 -- ae 1.148737907409668 -- time 2.338808298110962\n",
      "BC: 80\n",
      "Epoch 178: loss -18.848947525024414 -- ae 19.99579429626465 -- ae 1.1468257904052734 -- time 2.3193676471710205\n",
      "BC: 80\n",
      "Epoch 179: loss -18.85073471069336 -- ae 19.995817184448242 -- ae 1.145063042640686 -- time 2.30843186378479\n",
      "BC: 80\n",
      "Epoch 180: loss -18.852270126342773 -- ae 19.99584197998047 -- ae 1.1435534954071045 -- time 2.320622205734253\n",
      "BC: 80\n",
      "Epoch 181: loss -18.853939056396484 -- ae 19.995864868164062 -- ae 1.1419090032577515 -- time 2.2885756492614746\n",
      "BC: 80\n",
      "Epoch 182: loss -18.855573654174805 -- ae 19.995885848999023 -- ae 1.1403021812438965 -- time 2.2888901233673096\n",
      "BC: 80\n",
      "Epoch 183: loss -18.857425689697266 -- ae 19.995908737182617 -- ae 1.1384704113006592 -- time 2.3138184547424316\n",
      "BC: 80\n",
      "Epoch 184: loss -18.859111785888672 -- ae 19.99593162536621 -- ae 1.1368048191070557 -- time 2.2692766189575195\n",
      "BC: 80\n",
      "Epoch 185: loss -18.860849380493164 -- ae 19.995952606201172 -- ae 1.1350911855697632 -- time 2.306973695755005\n",
      "BC: 80\n",
      "Epoch 186: loss -18.862606048583984 -- ae 19.995975494384766 -- ae 1.1333556175231934 -- time 2.364060163497925\n",
      "BC: 80\n",
      "Epoch 187: loss -18.8643798828125 -- ae 19.995996475219727 -- ae 1.131601095199585 -- time 2.2868518829345703\n",
      "BC: 80\n",
      "Epoch 188: loss -18.865995407104492 -- ae 19.996017456054688 -- ae 1.1300069093704224 -- time 2.354353189468384\n",
      "BC: 80\n",
      "Epoch 189: loss -18.867704391479492 -- ae 19.99603843688965 -- ae 1.128318428993225 -- time 2.3636748790740967\n",
      "BC: 80\n",
      "Epoch 190: loss -18.86923599243164 -- ae 19.99605941772461 -- ae 1.1268115043640137 -- time 2.346912145614624\n",
      "BC: 80\n",
      "Epoch 191: loss -18.870819091796875 -- ae 19.996078491210938 -- ae 1.1252506971359253 -- time 2.33075213432312\n",
      "BC: 80\n",
      "Epoch 192: loss -18.87233543395996 -- ae 19.9960994720459 -- ae 1.1237601041793823 -- time 2.363661766052246\n",
      "BC: 80\n",
      "Epoch 193: loss -18.873952865600586 -- ae 19.99612045288086 -- ae 1.1221622228622437 -- time 2.40541672706604\n",
      "BC: 80\n",
      "Epoch 194: loss -18.875642776489258 -- ae 19.996139526367188 -- ae 1.1204935312271118 -- time 2.3420183658599854\n",
      "BC: 80\n",
      "Epoch 195: loss -18.877248764038086 -- ae 19.996158599853516 -- ae 1.1189074516296387 -- time 2.3456950187683105\n",
      "BC: 80\n",
      "Epoch 196: loss -18.878662109375 -- ae 19.996179580688477 -- ae 1.1175110340118408 -- time 2.4223854541778564\n",
      "BC: 80\n",
      "Epoch 197: loss -18.880094528198242 -- ae 19.996198654174805 -- ae 1.1160924434661865 -- time 2.3115718364715576\n",
      "BC: 80\n",
      "Epoch 198: loss -18.881637573242188 -- ae 19.996217727661133 -- ae 1.1145702600479126 -- time 2.367866277694702\n",
      "BC: 80\n",
      "Epoch 199: loss -18.88320541381836 -- ae 19.99623680114746 -- ae 1.1130180358886719 -- time 2.363142490386963\n",
      "BC: 80\n",
      "Epoch 200: loss -18.88486099243164 -- ae 19.99625587463379 -- ae 1.1113801002502441 -- time 2.3553659915924072\n",
      "BC: 80\n",
      "Epoch 201: loss -18.88645362854004 -- ae 19.996273040771484 -- ae 1.1098045110702515 -- time 2.372995138168335\n",
      "BC: 80\n",
      "Epoch 202: loss -18.88802146911621 -- ae 19.996292114257812 -- ae 1.108253836631775 -- time 2.3222439289093018\n",
      "BC: 80\n",
      "Epoch 203: loss -18.889541625976562 -- ae 19.996309280395508 -- ae 1.1067546606063843 -- time 2.3949782848358154\n",
      "BC: 80\n",
      "Epoch 204: loss -18.8909969329834 -- ae 19.996328353881836 -- ae 1.1053134202957153 -- time 2.4123387336730957\n",
      "BC: 80\n",
      "Epoch 205: loss -18.892578125 -- ae 19.99634552001953 -- ae 1.1037533283233643 -- time 2.339834213256836\n",
      "BC: 80\n",
      "Epoch 206: loss -18.894207000732422 -- ae 19.996362686157227 -- ae 1.10214102268219 -- time 2.341418504714966\n",
      "BC: 80\n",
      "Epoch 207: loss -18.89565658569336 -- ae 19.996381759643555 -- ae 1.1007074117660522 -- time 2.4089064598083496\n",
      "BC: 80\n",
      "Epoch 208: loss -18.897178649902344 -- ae 19.99639892578125 -- ae 1.099205732345581 -- time 2.3846826553344727\n",
      "BC: 80\n",
      "Epoch 209: loss -18.89855194091797 -- ae 19.996414184570312 -- ae 1.097847580909729 -- time 2.3514578342437744\n",
      "BC: 80\n",
      "Epoch 210: loss -18.9000244140625 -- ae 19.996431350708008 -- ae 1.0963928699493408 -- time 2.4233946800231934\n",
      "BC: 80\n",
      "Epoch 211: loss -18.901586532592773 -- ae 19.996448516845703 -- ae 1.094845175743103 -- time 2.370922088623047\n",
      "BC: 80\n",
      "Epoch 212: loss -18.90302085876465 -- ae 19.9964656829834 -- ae 1.0934245586395264 -- time 2.404226541519165\n",
      "BC: 80\n",
      "Epoch 213: loss -18.904460906982422 -- ae 19.99648094177246 -- ae 1.0920019149780273 -- time 2.458725690841675\n",
      "BC: 80\n",
      "Epoch 214: loss -18.905742645263672 -- ae 19.996498107910156 -- ae 1.0907353162765503 -- time 2.413268566131592\n",
      "BC: 80\n",
      "Epoch 215: loss -18.907194137573242 -- ae 19.99651336669922 -- ae 1.0893051624298096 -- time 2.400465726852417\n",
      "BC: 80\n",
      "Epoch 216: loss -18.908645629882812 -- ae 19.996530532836914 -- ae 1.0878677368164062 -- time 2.3976762294769287\n",
      "BC: 80\n",
      "Epoch 217: loss -18.910015106201172 -- ae 19.996545791625977 -- ae 1.0865139961242676 -- time 2.417754650115967\n",
      "BC: 80\n",
      "Epoch 218: loss -18.911415100097656 -- ae 19.99656105041504 -- ae 1.0851269960403442 -- time 2.4060051441192627\n",
      "BC: 80\n",
      "Epoch 219: loss -18.91292953491211 -- ae 19.996578216552734 -- ae 1.083626627922058 -- time 2.4019763469696045\n",
      "BC: 80\n",
      "Epoch 220: loss -18.914329528808594 -- ae 19.996593475341797 -- ae 1.0822412967681885 -- time 2.4131600856781006\n",
      "BC: 80\n",
      "Epoch 221: loss -18.915739059448242 -- ae 19.99660873413086 -- ae 1.0808466672897339 -- time 2.3651082515716553\n",
      "BC: 80\n",
      "Epoch 222: loss -18.91699981689453 -- ae 19.996623992919922 -- ae 1.079599142074585 -- time 2.462656021118164\n",
      "BC: 80\n",
      "Epoch 223: loss -18.918378829956055 -- ae 19.996639251708984 -- ae 1.0782300233840942 -- time 2.4250590801239014\n",
      "BC: 80\n",
      "Epoch 224: loss -18.91975975036621 -- ae 19.996652603149414 -- ae 1.0768600702285767 -- time 2.424701452255249\n",
      "BC: 80\n",
      "Epoch 225: loss -18.921024322509766 -- ae 19.996667861938477 -- ae 1.0756077766418457 -- time 2.463566303253174\n",
      "BC: 80\n",
      "Epoch 226: loss -18.922290802001953 -- ae 19.99668312072754 -- ae 1.0743566751480103 -- time 2.3836522102355957\n",
      "BC: 80\n",
      "Epoch 227: loss -18.92359733581543 -- ae 19.99669647216797 -- ae 1.0730657577514648 -- time 2.454362630844116\n",
      "BC: 80\n",
      "Epoch 228: loss -18.92500877380371 -- ae 19.99671173095703 -- ae 1.0716698169708252 -- time 2.4223897457122803\n",
      "BC: 80\n",
      "Epoch 229: loss -18.926420211791992 -- ae 19.996726989746094 -- ae 1.070273995399475 -- time 2.397913932800293\n",
      "BC: 80\n",
      "Epoch 230: loss -18.927696228027344 -- ae 19.996740341186523 -- ae 1.0690058469772339 -- time 2.422579526901245\n",
      "BC: 80\n",
      "Epoch 231: loss -18.928970336914062 -- ae 19.996753692626953 -- ae 1.0677489042282104 -- time 2.4498651027679443\n",
      "BC: 80\n",
      "Epoch 232: loss -18.930246353149414 -- ae 19.996768951416016 -- ae 1.0664857625961304 -- time 2.483654737472534\n",
      "BC: 80\n",
      "Epoch 233: loss -18.931554794311523 -- ae 19.996782302856445 -- ae 1.065191626548767 -- time 2.43634295463562\n",
      "BC: 80\n",
      "Epoch 234: loss -18.932722091674805 -- ae 19.996795654296875 -- ae 1.0640393495559692 -- time 2.524477481842041\n",
      "BC: 80\n",
      "Epoch 235: loss -18.933929443359375 -- ae 19.996809005737305 -- ae 1.0628467798233032 -- time 2.4933905601501465\n",
      "BC: 80\n",
      "Epoch 236: loss -18.935142517089844 -- ae 19.996822357177734 -- ae 1.0616494417190552 -- time 2.5194568634033203\n",
      "BC: 80\n",
      "Epoch 237: loss -18.936254501342773 -- ae 19.996835708618164 -- ae 1.0605560541152954 -- time 2.4707109928131104\n",
      "BC: 80\n",
      "Epoch 238: loss -18.93741798400879 -- ae 19.996849060058594 -- ae 1.059406042098999 -- time 2.423020124435425\n",
      "BC: 80\n",
      "Epoch 239: loss -18.938560485839844 -- ae 19.996862411499023 -- ae 1.0582756996154785 -- time 2.4687275886535645\n",
      "BC: 80\n",
      "Epoch 240: loss -18.93968391418457 -- ae 19.996875762939453 -- ae 1.0571660995483398 -- time 2.4165239334106445\n",
      "BC: 80\n",
      "Epoch 241: loss -18.94099998474121 -- ae 19.996889114379883 -- ae 1.0558654069900513 -- time 2.6595523357391357\n",
      "BC: 80\n",
      "Epoch 242: loss -18.942358016967773 -- ae 19.99690055847168 -- ae 1.0545164346694946 -- time 2.505042552947998\n",
      "BC: 80\n",
      "Epoch 243: loss -18.94361686706543 -- ae 19.99691390991211 -- ae 1.0532597303390503 -- time 2.4870662689208984\n",
      "BC: 80\n",
      "Epoch 244: loss -18.944791793823242 -- ae 19.99692726135254 -- ae 1.0520943403244019 -- time 2.4660732746124268\n",
      "BC: 80\n",
      "Epoch 245: loss -18.945934295654297 -- ae 19.996938705444336 -- ae 1.0509648323059082 -- time 2.5522756576538086\n",
      "BC: 80\n",
      "Epoch 246: loss -18.947134017944336 -- ae 19.996952056884766 -- ae 1.0497833490371704 -- time 2.5676491260528564\n",
      "BC: 80\n",
      "Epoch 247: loss -18.948415756225586 -- ae 19.996963500976562 -- ae 1.0485121011734009 -- time 2.4772629737854004\n",
      "BC: 80\n",
      "Epoch 248: loss -18.949586868286133 -- ae 19.996976852416992 -- ae 1.047351360321045 -- time 2.464927911758423\n",
      "BC: 80\n",
      "Epoch 249: loss -18.95077133178711 -- ae 19.99698829650879 -- ae 1.046187162399292 -- time 2.490568161010742\n",
      "saving weights\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "print(len(x_train))\n",
    "x_train_t = x_train[:8000]\n",
    "y_train_t = y_train[:8000]\n",
    "cae.train(x_train_t, y_train_t,\n",
    "                1e-1, 1, 1, 1, 1,\n",
    "                1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from cifar10_robust_models import Load_Madry_Model, cifar10_tf_robust_models\n",
    "\n",
    "tvars_vals = []\n",
    "\n",
    "class ContrastiveAE(object):\n",
    "    def __init__(self, optimizer, lr, dims = 1, verbose=1):\n",
    "        self.dims = dims\n",
    "        self.optimizer = optimizer(lr)\n",
    "        self.verbose = verbose\n",
    "        print(\"init\")\n",
    "    \n",
    "    def train(self, X_train, y_train, actual_labels,\n",
    "              lambda_1, batch_size, epochs, similar_ratio, margin,\n",
    "              weights_save_name, display_interval):\n",
    "        \"\"\"Train an autoencoder with standard mse loss + contrastive loss.\n",
    "        Arguments:\n",
    "            X_train {numpy.ndarray} -- feature vectors of the training data\n",
    "            y_train {numpy.ndarray} -- ground-truth labels of the training data\n",
    "            lambda_1 {float} -- balance factor for the autoencoder reconstruction loss and contrastive loss\n",
    "            batch_size {int} -- number of samples in each batch (note we only use **half of batch_size**\n",
    "                                from the training data).\n",
    "            epochs {int} -- No. of maximum epochs.\n",
    "            similar_ratio {float} -- ratio of similar samples, use 0.25 for now.\n",
    "            margin {float} -- the hyper-parameter m.\n",
    "            weights_save_name {str} -- file path to save the best weights files.\n",
    "            display_interval {int} -- print traning logs per {display_interval} epoches\n",
    "        \"\"\"\n",
    "        print(\"hello\")\n",
    "        if False:\n",
    "            logging.info('weights file exists, no need to train contrastive AE')\n",
    "        else:\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "           \n",
    "            lambda_1_tensor = tf.placeholder(tf.float32)\n",
    "            ae = Autoencoder(self.dims)\n",
    "            ae_model, encoder_model = ae.build()\n",
    "\n",
    "            input_ = ae_model.get_input_at(0)\n",
    "            labels = ae_model.get_input_at(0)\n",
    "            aclabels = tf.placeholder(tf.float32, [None, 1])\n",
    "            # add loss function -- for efficiency and not doubling the network's weights, we pass a batch of samples and\n",
    "            # make the pairs from it at the loss level.\n",
    "#             left_p = tf.convert_to_tensor(list(range(0, int(batch_size / 2))), np.int32)\n",
    "#             right_p = tf.convert_to_tensor(list(range(int(batch_size / 2), batch_size)), np.int32)\n",
    "\n",
    "#             # left_p: indices with all the data in this batch, right_p: half with similar data compared to left_p, half with dissimilar data compared to left_p\n",
    "#             # if batch_size = 16 (but only using 8 samples in this batch):\n",
    "#             # e.g., left_p labels: 1, 2, 4, 8 | 2, 3, 5, 6\n",
    "#             #      right_p labels: 1, 2, 4, 8 | 3, 4, 1, 7\n",
    "#             # check whether labels[left_p] == labels[right_p] for each element\n",
    "#             is_same = tf.cast(tf.equal(tf.gather(labels, left_p), tf.gather(labels, right_p)), tf.float32)\n",
    "#             # NOTE: add a small number like 1e-10 would prevent tf.sqrt() to have 0 values, further leading gradients and loss all NaN.\n",
    "#             # check: https://stackoverflow.com/questions/33712178/tensorflow-nan-bug\n",
    "#             dist = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.gather(ae.encoded, left_p), tf.gather(ae.encoded, right_p))), 1) + 1e-10) # ||zi - zj||_2\n",
    "#             contrastive_loss = tf.multiply(is_same, dist) # y_ij = 1 means the same class.\n",
    "#             contrastive_loss = contrastive_loss + tf.multiply((tf.constant(1.0) - is_same), tf.nn.relu(margin - dist))  # as relu(z) = max(0, z)\n",
    "#             contrastive_loss = tf.reduce_mean(contrastive_loss)\n",
    "\n",
    "            aeoutput = ae_model(input_)\n",
    "            ae_loss = tf.keras.losses.MSE(input_, ae_model(input_)) # ae.out equals ae_model(input_)\n",
    "            ae_loss = tf.reduce_mean(ae_loss)\n",
    "            \n",
    "            model_dir = \"./\"\n",
    "#             target_model2 = Load_Madry_Model(tf.Session(config=config), model_dir, input_, bias = 0.5, scale = 255)\n",
    "#             target_model3 = Load_Madry_Model(tf.Session(config=config), model_dir, aeoutput, bias = 0.5, scale = 255)\n",
    "            \n",
    "#             output = tf.identity(target_model2.model.softmax_pred, name='my_output')\n",
    "#             output2 = tf.identity(target_model3.model.softmax_pred, name='my_output2')\n",
    "            \n",
    "#             cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "#             loss = cce(aclabels, output2) + ae_loss\n",
    "\n",
    "            train_op = self.optimizer.minimize(ae_loss, var_list=tf.trainable_variables())\n",
    "\n",
    "            # Start training\n",
    "            with tf.Session(config=config) as sess:\n",
    "                loss_batch, aux_batch = [], []\n",
    "                contrastive_loss_batch, ae_loss_batch = [], []\n",
    "                \n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                #target_model2.load_weights()\n",
    "                min_loss = np.inf\n",
    "                \n",
    "                #print(list(set(tf.trainable_variables()) - target_model2.var_list - target_model3.var_list))    \n",
    "                \n",
    "                # epoch training loop\n",
    "                for epoch in range(100):\n",
    "                    epoch_time = time.time()\n",
    "                    # split data into batches\n",
    "#                     batch_count, batch_x, batch_y = data.epoch_batches(X_train, y_train,\n",
    "#                                         %%!                            batch_size,\n",
    "#                                                                     similar_ratio)\n",
    "#                     # batch training loop\n",
    "                    \n",
    "                    for b in range(1):\n",
    "                        logging.debug(f'b: {b}')\n",
    "                    \n",
    "                        feed_dict = {\n",
    "                            input_: x_train,\n",
    "                            labels: y_train,\n",
    "                            lambda_1_tensor: lambda_1,\n",
    "                            aclabels: actual_labels,\n",
    "                        }\n",
    "#                         loss1, _, ae_loss1, \\\n",
    "#                             encoded1, labelled = sess.run([loss, train_op, ae_loss, ae.encoded, target_model2.model.softmax_pred], feed_dict=feed_dict)\n",
    "                        ae_loss1, _ = sess.run([ae_loss, train_op], feed_dict=feed_dict)\n",
    "                        loss1 = 0\n",
    "                        #ae_loss1 = 0\n",
    "                        \n",
    "                        #print(np.argmax(labelled, axis=1))\n",
    "                        #print(np.argmax(labelled2, axis=1))\n",
    "                        #print(labelled)\n",
    "                        print(f'loss1: {ae_loss1},  aux1: -')\n",
    "#                         logging.debug(f'contrastive: {contrastive_loss1}, ae: {ae_loss1}')\n",
    "#                         logging.debug(f'epoch-{epoch} dist1[left]: {dist1[0:batch_size // 4]}')\n",
    "#                         logging.debug(f'epoch-{epoch} dist1[right]: {dist1[batch_size // 4:]}')\n",
    "        \n",
    "                        loss_batch.append(loss1)\n",
    "#                         aux_batch.append(aux1)\n",
    "#                         contrastive_loss_batch.append(contrastive_loss1)\n",
    "                        ae_loss_batch.append(ae_loss1)\n",
    "\n",
    "                    if math.isnan(np.mean(loss_batch)):\n",
    "                        logging.error('NaN value in loss')\n",
    "                    \n",
    "                    current_loss = np.mean(loss_batch)\n",
    "#                     #print(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "#                                     f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "#                                     f'time {time.time() - epoch_time}')\n",
    "                    # print logs each xxx epoch\n",
    "#                     if epoch % display_interval == 0:\n",
    "#                         current_loss = np.mean(loss_batch)\n",
    "#                         logging.info(f'Epoch {epoch}: loss {current_loss} -- ' + \\\n",
    "#                                     f'contrastive {np.mean(contrastive_loss_batch)} -- ' + \\\n",
    "#                                     f'ae {np.mean(ae_loss_batch)} -- ' + \\\n",
    "#                                     f'pairs {np.mean(np.sum(np.mean(aux_batch)))} : ' + \\\n",
    "#                                     f'{np.mean(np.sum(1-np.mean(aux_batch)))} -- ' + \\\n",
    "#                                     f'time {time.time() - epoch_time}')\n",
    "#                         loss_batch, aux_batch = [], []\n",
    "#                         contrastive_loss_batch, ae_loss_batch = [], []\n",
    "\n",
    "#                         # save best weights\n",
    "#                         if current_loss < min_loss:\n",
    "#                             logging.info(f'updating best loss from {min_loss} to {current_loss}')\n",
    "#                             min_loss = current_loss\n",
    "#                             ae_model.save_weights(weights_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "OPTIMIZER = tf.train.AdamOptimizer\n",
    "cae = ContrastiveAE(OPTIMIZER, 0.01)\n",
    "x_train_vis = x_train[2:3]\n",
    "cae.visualize(x_train_vis, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
